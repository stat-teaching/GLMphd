{
  "hash": "09a9e887471f98ba5a3023efc92ede2a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"GLM Diagnostics\"\n---\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ Loading test\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ ggplot2::qplot() masks test::qplot()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n:::\n\n\n\n\nThe model diagnostics are a set of tools (plots, statistics, etc.) used to evaluate if the assumptions hold and indentify patterns of poor fitting.\n\n## Observed vs simulated data\n\nMonte Carlo simulations can be used to assess the quality of a fitted model by comparing observed with simulated data. A discrepancy between real and simulated data could inform about model misspecifications such as missing predictors, wrong predictors transformations (e.g., log vs linear) or wrong assumed distributions (e.g., Gaussian instead of Gamma for bounded and skewed data).\n\nLet's simulate a Poisson model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 1e3\nx <- runif(N, 0, 100)\ny <- rpois(N, exp(log(5) + log(1.01) * x))\n\nhist(y)\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(x, y)\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndat <- data.frame(y, x)\n```\n:::\n\n\n\nNow let's fit a standard linear model and a generalized linear model with a Poisson distribution and log link function:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_lm <- lm(y ~ x, data = dat)\nfit_glm <- glm(y ~ x, data = dat, family = poisson(link = \"log\"))\n```\n:::\n\n\n\nWe want to focus only on predictions and not about intepreting parameters. See [Poisson GLM](../slides/03-poisson-glm/03-poisson-glm.qmd) for parameters intepretation.\n\nWe can use the `simulate()` function to generate, given the fitted model, new observations:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(simulate(fit_lm))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      sim_1\n1  9.737471\n2  7.497207\n3 -0.775709\n4 10.008600\n5 14.830918\n6  4.027253\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(simulate(fit_glm))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  sim_1\n1    20\n2    10\n3     7\n4     7\n5     7\n6     3\n```\n\n\n:::\n:::\n\n\n\nWe already see an important differences related to the type of generated data. The `fit_glm` model correctly generates discrete data that are similar to the observed data. The `fit_lm` on the other side generates continous data because is assuming a Gaussian distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_lm <- simulate(fit_lm)\npp_glm <- simulate(fit_glm)\n\n# adding the observed data\npp_lm$y <- dat$y\npp_glm$y <- dat$y\n\nggplot(pp_lm, aes(x = y)) +\n  geom_density(col = \"firebrick\", lwd = 1) +\n  geom_density(aes(x = sim_1)) +\n  ggtitle(\"Linear Model\")\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(pp_glm, aes(x = y)) +\n  geom_density(col = \"firebrick\", lwd = 1) +\n  geom_density(aes(x = sim_1)) +\n  ggtitle(\"Generalized Linear Model\")\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\n\nWe can generate $B$ datasets to see the range of simulated data compared to the observed data. This can be done with the `performance::check_prediction()` function:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::check_predictions(fit_lm)\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nperformance::check_predictions(fit_glm)\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\n\n## Checking the link function\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 1e3\nshape <- 5\nx <- runif(N, 0, 100)\nlp <- log(10) + log(1.01) * x\ny <- rgamma(N, shape, scale = exp(lp)/shape)\n\nfit_log <- glm(y ~ x, family = Gamma(link = \"log\"))\nfit_inv <- glm(y ~ x, family = Gamma(link = \"inverse\"))\n\npar(mfrow = c(1,2))\nplot(predict(fit_log), resid(fit_log, type = \"working\"))\nplot(predict(fit_inv), resid(fit_inv, type = \"working\"))\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 1e3\nx <- runif(N, 0, 1)\nlp <- qlogis(0.01) + 10 * x\np <- plogis(lp)\ny <- rbinom(N, 1, p)\n\nfit_logit <- glm(y ~ x, family = binomial(link = \"logit\"))\nfit_probit <- glm(y ~ x, family = binomial(link = \"probit\"))\n\nri_logit <- resid(fit_logit, type = \"working\")\nri_probit <- resid(fit_probit, type = \"working\")\n\nplot(predict(fit_logit), ri_logit)\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(predict(fit_probit), ri_probit)\n```\n\n::: {.cell-output-display}\n![](glm-diagnostic_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\n\n## GLM assumptions\n\nFrom @Dunn2018-ww, the assumptions made when ﬁtting glms concern:\n\n- Lack of outliers: All responses were generated from the same process, so\nthat the same model is appropriate for all the observations.\n- Link function: The correct link function $g(\\cdot)$ is used.\n- Linearity: All important explanatory variables are included, and each\nexplanatory variable is included in the linear predictor on the correct\nscale.\n- Variance function: The correct variance function $V(\\mu)$ is used.\n- Dispersion parameter: The dispersion parameter $\\phi$ is constant.\n- Independence: The responses $y_i$ are independent of each other.\n- Distribution: The responses $y_i$ come from the speciﬁed edm.\n\n## Residuals\n\n### Response Residuals\n\nResponse residuals are defined as:\n\n$$\nr_i = y_i - \\hat{\\mu}_i\n$$\n\nThese residuals are problematic because most of the time mean and variance are linked in GLMs, thus the same raw residual is not intepreted in the same way along the mean-variance relationship.\n\n### Pearson Residuals\n\n<!-- Agresti says something about pearson residuals -->\n\nShould be normally distributed under some conditions.\n\n### Deviance Residuals\n\nShould be normally distributed under some conditions.\n\n### Quantile Residuals\n\n\n# Resources\n\n- [https://rpubs.com/benhorvath/glm_diagnostics](https://rpubs.com/benhorvath/glm_diagnostics)\n",
    "supporting": [
      "glm-diagnostic_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}