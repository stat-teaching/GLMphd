{
  "hash": "4190077209aa331976063cf8d862dedf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 3\"\nformat: html\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndevtools::load_all() # if using the rproject dowloaded from the slides\n# source(\"utils-glm.R\") # if using a standard setup\nlibrary(here)\nlibrary(tidyr) # for data manipulation\nlibrary(dplyr) # for data manipulation\nlibrary(ggplot2) # plotting\nlibrary(car) # general utilities\nlibrary(effects) # for extracting and plotting effects \nlibrary(emmeans) # for marginal means\nlibrary(patchwork)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"drop\")\ndat <- drop\n```\n:::\n\n\n\n# Overview\n\nThis dataset `dropout.csv` contains data about dropouts during high school for `nrow(dat)` adolescents. We want to understand the impact of the parenting style (permissive, neglectful, authoritative, authoritarian) and the academic performance (high, low) on the probability of dropout (0 = no dropout, 1 = dropout).\n\n1. Importing data and overall check\n2. Exploratory data analysis of predictors and the relationships between predictors and the number of words\n3. Compute the odds ratio manually comparing the academic performances for each parenting style\n4. Model fitting with `glm()` using the dataset in the binary form\n5. Model fitting with `glm()` using the dataset in the aggregated form\n6. Plotting and interpreting effects of both models\n    - is there any difference? try to understand why\n7. Write a brief paragraph reporting the effects with your interpretation\n\n# 1. Importing data and overall check\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t500 obs. of  4 variables:\n $ id       : int  1 2 3 4 5 6 7 8 9 10 ...\n $ parenting: chr  \"permissive\" \"neglectful\" \"authoritative\" \"neglectful\" ...\n $ academic : chr  \"high\" \"low\" \"high\" \"low\" ...\n $ drop     : int  0 0 0 1 0 0 0 0 0 0 ...\n```\n\n\n:::\n:::\n\n\n\nCheck for `NA` values:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsapply(dat, function(x) sum(is.na(x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       id parenting  academic      drop \n        0         0         0         0 \n```\n\n\n:::\n:::\n\n\n\nEverything seems good, we do not have `NA` values.\n\nLet's convert categorical variables into factor setting the appropriate order:\n\n- `parenting`: neglectful, permissive, authoritative, authoritarian\n- `academic`: low, high\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$parenting <- factor(dat$parenting, levels = c(\"neglectful\",\n                                                  \"permissive\",\n                                                  \"authoritative\",\n                                                  \"authoritarian\"))\ndat$academic <- factor(dat$academic, levels = c(\"low\", \"high\"))\n\nlevels(dat$parenting)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"neglectful\"    \"permissive\"    \"authoritative\" \"authoritarian\"\n```\n\n\n:::\n\n```{.r .cell-code}\nlevels(dat$academic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"low\"  \"high\"\n```\n\n\n:::\n:::\n\n\n\n# 2. Exploratory data analysis\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(dat) # not really meaningful\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       id                parenting   academic        drop      \n Min.   :  1.0   neglectful   :119   low :237   Min.   :0.000  \n 1st Qu.:125.8   permissive   :152   high:263   1st Qu.:0.000  \n Median :250.5   authoritative:124              Median :0.000  \n Mean   :250.5   authoritarian:105              Mean   :0.166  \n 3rd Qu.:375.2                                  3rd Qu.:0.000  \n Max.   :500.0                                  Max.   :1.000  \n```\n\n\n:::\n:::\n\n\n\nWith categorical variables we need to use absolute/relative frequencies and contingency tables.\n\nLet's start by univariate EDA:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# distribution of parenting styles\ntable(dat$parenting)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   neglectful    permissive authoritative authoritarian \n          119           152           124           105 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(dat$parenting)/nrow(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   neglectful    permissive authoritative authoritarian \n        0.238         0.304         0.248         0.210 \n```\n\n\n:::\n\n```{.r .cell-code}\n# distribution of academic performance\ntable(dat$academic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n low high \n 237  263 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(dat$academic)/nrow(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  low  high \n0.474 0.526 \n```\n\n\n:::\n\n```{.r .cell-code}\n# overall dropout rate\ntable(dat$drop)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  0   1 \n417  83 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(dat$drop)/nrow(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    0     1 \n0.834 0.166 \n```\n\n\n:::\n\n```{.r .cell-code}\n# mean(dat$drop) # directly\n```\n:::\n\n\n\nLet's create an overall plot:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplt_par <- dat |> \n  ggplot(aes(x = parenting)) +\n  geom_bar()\n\nplt_academic <- dat |> \n  ggplot(aes(x = academic)) +\n  geom_bar()\n\nplt_drop <- dat |> \n  ggplot(aes(x = factor(drop))) +\n  geom_bar()\n\nplt_par / plt_academic / plt_drop\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-6-1.svg){width=960}\n:::\n:::\n\n\n\nHow to interpret?\n\nLet's now explore the bivariate relationships:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(dat$parenting, dat$academic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n                low high\n  neglectful     95   24\n  permissive     77   75\n  authoritative  20  104\n  authoritarian  45   60\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(dat$academic, dat$parenting)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      \n       neglectful permissive authoritative authoritarian\n  low          95         77            20            45\n  high         24         75           104            60\n```\n\n\n:::\n:::\n\n\n\nWe can create tables with relative frequencies:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.table(table(dat$parenting, dat$academic), 1) # by row\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n                      low      high\n  neglectful    0.7983193 0.2016807\n  permissive    0.5065789 0.4934211\n  authoritative 0.1612903 0.8387097\n  authoritarian 0.4285714 0.5714286\n```\n\n\n:::\n\n```{.r .cell-code}\nprop.table(table(dat$parenting, dat$academic), 2) # by column\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n                       low       high\n  neglectful    0.40084388 0.09125475\n  permissive    0.32489451 0.28517110\n  authoritative 0.08438819 0.39543726\n  authoritarian 0.18987342 0.22813688\n```\n\n\n:::\n:::\n\n\n\n...and some plots:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat |> \n  ggplot(aes(x = academic, fill = parenting)) +\n  geom_bar(position = position_dodge(),\n           col = \"black\")\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-9-1.svg){width=672}\n:::\n:::\n\n\n\nOf course, we can compute the relative frequencies in multiple ways (total, row or column wise).\n\nThen the bivariate relationships with the `drop` variable:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(dat$parenting, dat$drop)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n                  0   1\n  neglectful     76  43\n  permissive    136  16\n  authoritative 117   7\n  authoritarian  88  17\n```\n\n\n:::\n\n```{.r .cell-code}\nprop.table(table(dat$parenting, dat$drop), 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               \n                         0          1\n  neglectful    0.63865546 0.36134454\n  permissive    0.89473684 0.10526316\n  authoritative 0.94354839 0.05645161\n  authoritarian 0.83809524 0.16190476\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(dat$academic, dat$drop)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      \n         0   1\n  low  174  63\n  high 243  20\n```\n\n\n:::\n\n```{.r .cell-code}\nprop.table(table(dat$academic, dat$drop), 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      \n                0          1\n  low  0.73417722 0.26582278\n  high 0.92395437 0.07604563\n```\n\n\n:::\n:::\n\n\n\nAnd the plots:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbarplot(prop.table(table(dat$parenting, dat$drop), 1), \n        beside = TRUE,\n        col = c(\"firebrick\", \"lightblue\", \"darkgreen\", \"pink\"))\n\nlegend(7, 0.8, legend = levels(dat$parenting), \n       fill = c(\"firebrick\", \"lightblue\", \"darkgreen\", \"pink\"))\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-11-1.svg){width=672}\n:::\n\n```{.r .cell-code}\nbarplot(prop.table(table(dat$parenting, dat$drop), 1), \n        beside = TRUE,\n        col = c(\"firebrick\", \"lightblue\", \"darkgreen\", \"pink\"))\n\nlegend(7, 0.8, legend = levels(dat$parenting), \n       fill = c(\"firebrick\", \"lightblue\", \"darkgreen\", \"pink\"))\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-11-2.svg){width=672}\n:::\n\n```{.r .cell-code}\nbarplot(prop.table(table(dat$academic, dat$drop), 1), \n        beside = TRUE,\n        col = c(\"red\", \"blue\"))\n\nlegend(4, 0.5, legend = levels(dat$academic), \n       fill =  c(\"red\", \"blue\"))\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-11-3.svg){width=672}\n:::\n:::\n\n\n\nFinally we can represent the full relationship:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat |> \n  group_by(parenting, academic) |> \n  summarise(drop = mean(drop)) |> \n  ggplot(aes(x = parenting, y = drop, color = academic, group = academic)) +\n  geom_point() +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-12-1.svg){width=672}\n:::\n:::\n\n\n\nComments? Main effects? Interactions?\n\n# 3. Compute the odds ratio manually comparing the academic performances for each parenting style\n\nFirstly we compute the probability of dropout for each category:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nagg <- aggregate(drop ~ parenting + academic, FUN = mean, data = dat)\nagg\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      parenting academic       drop\n1    neglectful      low 0.37894737\n2    permissive      low 0.19480519\n3 authoritative      low 0.15000000\n4 authoritarian      low 0.20000000\n5    neglectful     high 0.29166667\n6    permissive     high 0.01333333\n7 authoritative     high 0.03846154\n8 authoritarian     high 0.13333333\n```\n\n\n:::\n:::\n\n\n\nThen we can compute the odds of the probabilities and the odds ratios\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nodds <- function(p) p / (1 - p)\nagg$odds <- odds(agg$drop)\n\nors <- agg$odds[agg$academic == \"high\"] / agg$odds[agg$academic == \"low\"]\nnames(ors) <- unique(agg$parenting)\nors\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   neglectful    permissive authoritative authoritarian \n   0.67483660    0.05585586    0.22666667    0.61538462 \n```\n\n\n:::\n:::\n\n\n\nComments?\n\n# 4. Model fitting with `glm()` using the dataset in the binary form\n\nLet's start fitting the null model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit0 <- glm(drop ~ 1, data = dat, family = binomial(link = \"logit\"))\nsummary(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = drop ~ 1, family = binomial(link = \"logit\"), data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.6142     0.1202  -13.43   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 449.49  on 499  degrees of freedom\nResidual deviance: 449.49  on 499  degrees of freedom\nAIC: 451.49\n\nNumber of Fisher Scoring iterations: 3\n```\n\n\n:::\n:::\n\n\n\nThe intercept is the overall odds of dropout:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(coef(fit0))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) \n  0.1990408 \n```\n\n\n:::\n\n```{.r .cell-code}\nplogis(coef(fit0))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) \n      0.166 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(dat$drop)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.166\n```\n\n\n:::\n:::\n\n\n\nLet's now fit a model with the two main effects:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- glm(drop ~ academic + parenting, data = dat, family = binomial(link = \"logit\"))\nsummary(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = drop ~ academic + parenting, family = binomial(link = \"logit\"), \n    data = dat)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(>|z|)    \n(Intercept)             -0.3921     0.1985  -1.975 0.048216 *  \nacademichigh            -1.0221     0.3030  -3.373 0.000742 ***\nparentingpermissive     -1.3446     0.3335  -4.031 5.55e-05 ***\nparentingauthoritative  -1.6402     0.4670  -3.512 0.000444 ***\nparentingauthoritarian  -0.7550     0.3412  -2.212 0.026935 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 449.49  on 499  degrees of freedom\nResidual deviance: 392.66  on 495  degrees of freedom\nAIC: 402.66\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n\nComments?\n\nLet's now fit the interaction model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- glm(drop ~ academic * parenting, data = dat, family = binomial(link = \"logit\"))\nsummary(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = drop ~ academic * parenting, family = binomial(link = \"logit\"), \n    data = dat)\n\nCoefficients:\n                                    Estimate Std. Error z value Pr(>|z|)   \n(Intercept)                         -0.49402    0.21149  -2.336  0.01950 * \nacademichigh                        -0.39328    0.49639  -0.792  0.42820   \nparentingpermissive                 -0.92507    0.35710  -2.590  0.00958 **\nparentingauthoritative              -1.24058    0.66097  -1.877  0.06053 . \nparentingauthoritarian              -0.89228    0.42850  -2.082  0.03731 * \nacademichigh:parentingpermissive    -2.49170    1.15811  -2.152  0.03144 * \nacademichigh:parentingauthoritative -1.09099    0.94793  -1.151  0.24976   \nacademichigh:parentingauthoritarian -0.09222    0.72769  -0.127  0.89915   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 449.49  on 499  degrees of freedom\nResidual deviance: 384.58  on 492  degrees of freedom\nAIC: 400.58\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n\n# 5. Model fitting with `glm()` using the dataset in the aggregated form\n\nIn this case we can easily fit the same model using the aggregated form. The aggregated form is a dataset without 1s and 0s but counting the number of 1s for each condition.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_agg <- dat |> \n    group_by(academic, parenting) |> \n    summarise(drop_1 = sum(drop),\n              drop_0 = sum(drop == 0)) |> \n    data.frame()\n\ndat_agg$drop_tot <- dat_agg$drop_1 + dat_agg$drop_0\n```\n:::\n\n\n\nNow we have a column with the number of 1s and a column with the total. Then we can also compute the number of 0s:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_agg\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  academic     parenting drop_1 drop_0 drop_tot\n1      low    neglectful     36     59       95\n2      low    permissive     15     62       77\n3      low authoritative      3     17       20\n4      low authoritarian      9     36       45\n5     high    neglectful      7     17       24\n6     high    permissive      1     74       75\n7     high authoritative      4    100      104\n8     high authoritarian      8     52       60\n```\n\n\n:::\n:::\n\n\n\nThe two dataset (`dat` and `dat_agg`) contains the same information. Let's now fit the same models as before:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit0_agg <- glm(cbind(drop_1, drop_0) ~ 1, data = dat_agg, family = binomial(link = \"logit\"))\nsummary(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = drop ~ 1, family = binomial(link = \"logit\"), data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.6142     0.1202  -13.43   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 449.49  on 499  degrees of freedom\nResidual deviance: 449.49  on 499  degrees of freedom\nAIC: 451.49\n\nNumber of Fisher Scoring iterations: 3\n```\n\n\n:::\n:::\n\n\n\nLet's now fit a model with the two main effects:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1_agg <- glm(cbind(drop_1, drop_0) ~ academic + parenting, data = dat_agg, family = binomial(link = \"logit\"))\nsummary(fit1_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cbind(drop_1, drop_0) ~ academic + parenting, family = binomial(link = \"logit\"), \n    data = dat_agg)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(>|z|)    \n(Intercept)             -0.3921     0.1985  -1.975 0.048216 *  \nacademichigh            -1.0221     0.3030  -3.373 0.000742 ***\nparentingpermissive     -1.3446     0.3335  -4.031 5.54e-05 ***\nparentingauthoritative  -1.6402     0.4670  -3.512 0.000444 ***\nparentingauthoritarian  -0.7550     0.3412  -2.212 0.026935 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 64.902  on 7  degrees of freedom\nResidual deviance:  8.079  on 3  degrees of freedom\nAIC: 46.507\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\nComments?\n\nLet's now fit the interaction model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2_agg <- glm(cbind(drop_1, drop_0) ~ academic * parenting, data = dat_agg, family = binomial(link = \"logit\"))\nsummary(fit2_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cbind(drop_1, drop_0) ~ academic * parenting, family = binomial(link = \"logit\"), \n    data = dat_agg)\n\nCoefficients:\n                                    Estimate Std. Error z value Pr(>|z|)   \n(Intercept)                         -0.49402    0.21149  -2.336  0.01950 * \nacademichigh                        -0.39328    0.49639  -0.792  0.42820   \nparentingpermissive                 -0.92507    0.35710  -2.590  0.00958 **\nparentingauthoritative              -1.24058    0.66097  -1.877  0.06053 . \nparentingauthoritarian              -0.89228    0.42850  -2.082  0.03731 * \nacademichigh:parentingpermissive    -2.49170    1.15876  -2.150  0.03153 * \nacademichigh:parentingauthoritative -1.09099    0.94793  -1.151  0.24976   \nacademichigh:parentingauthoritarian -0.09222    0.72769  -0.127  0.89915   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6.4902e+01  on 7  degrees of freedom\nResidual deviance: 2.6645e-15  on 0  degrees of freedom\nAIC: 44.428\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\nDo you notice any difference with the previous models?\n\n# 6. Plotting and interpreting effects of both models\n\nLet's start by plotting the full model (in both forms):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(allEffects(fit2))\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-24-1.svg){width=672}\n:::\n\n```{.r .cell-code}\nplot(allEffects(fit2_agg))\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-24-2.svg){width=672}\n:::\n:::\n\n\n\nLet's compare the coefficients:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::compareCoefs(fit2, fit2_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCalls:\n1: glm(formula = drop ~ academic * parenting, family = binomial(link = \n  \"logit\"), data = dat)\n2: glm(formula = cbind(drop_1, drop_0) ~ academic * parenting, family = \n  binomial(link = \"logit\"), data = dat_agg)\n\n                                    Model 1 Model 2\n(Intercept)                          -0.494  -0.494\nSE                                    0.211   0.211\n                                                   \nacademichigh                         -0.393  -0.393\nSE                                    0.496   0.496\n                                                   \nparentingpermissive                  -0.925  -0.925\nSE                                    0.357   0.357\n                                                   \nparentingauthoritative               -1.241  -1.241\nSE                                    0.661   0.661\n                                                   \nparentingauthoritarian               -0.892  -0.892\nSE                                    0.429   0.429\n                                                   \nacademichigh:parentingpermissive      -2.49   -2.49\nSE                                     1.16    1.16\n                                                   \nacademichigh:parentingauthoritative  -1.091  -1.091\nSE                                    0.948   0.948\n                                                   \nacademichigh:parentingauthoritarian -0.0922 -0.0922\nSE                                   0.7277  0.7277\n                                                   \n```\n\n\n:::\n:::\n\n\n\nNow let's interpret the effects. The \"new\" component is the interaction between two categorical variable. If the coefficients with one categorical variable is the log(Odds Ratio), the interaction is the difference between the two odds ratios. When transformed on the probability scale, the parameter is the ratio between odds ratios.\n\nThis is the odds ratio for the academic effect with neglectful parenting (i.e., the reference level):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefs <- coef(fit2_agg)\n\ncoefs[\"academichigh\"] # log odds ratio\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nacademichigh \n  -0.3932847 \n```\n\n\n:::\n\n```{.r .cell-code}\nexp(coefs[\"academichigh\"]) # odds ratio\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nacademichigh \n   0.6748366 \n```\n\n\n:::\n\n```{.r .cell-code}\nagg\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      parenting academic       drop       odds\n1    neglectful      low 0.37894737 0.61016949\n2    permissive      low 0.19480519 0.24193548\n3 authoritative      low 0.15000000 0.17647059\n4 authoritarian      low 0.20000000 0.25000000\n5    neglectful     high 0.29166667 0.41176471\n6    permissive     high 0.01333333 0.01351351\n7 authoritative     high 0.03846154 0.04000000\n8 authoritarian     high 0.13333333 0.15384615\n```\n\n\n:::\n\n```{.r .cell-code}\nlow <- agg$odds[agg$parenting == \"neglectful\" & agg$academic == \"low\"]\nhigh <- agg$odds[agg$parenting == \"neglectful\" & agg$academic == \"high\"]\n\nhigh/low\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6748366\n```\n\n\n:::\n\n```{.r .cell-code}\nlog(high/low)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.3932847\n```\n\n\n:::\n:::\n\n\n\nThen the `academichigh:parentingpermissive` is the difference of the log odds ratios for low vs high for neglectful and permissive parenting styles.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefs[\"academichigh:parentingpermissive\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nacademichigh:parentingpermissive \n                       -2.491696 \n```\n\n\n:::\n\n```{.r .cell-code}\nexp(coefs[\"academichigh:parentingpermissive\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nacademichigh:parentingpermissive \n                      0.08276945 \n```\n\n\n:::\n\n```{.r .cell-code}\nlow_neg <- agg$odds[agg$parenting == \"neglectful\" & agg$academic == \"low\"]\nhigh_neg <- agg$odds[agg$parenting == \"neglectful\" & agg$academic == \"high\"]\nlow_per <- agg$odds[agg$parenting == \"permissive\" & agg$academic == \"low\"]\nhigh_per <- agg$odds[agg$parenting == \"permissive\" & agg$academic == \"high\"]\n\nlog((high_per / low_per)) - log((high_neg / low_neg))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -2.491696\n```\n\n\n:::\n\n```{.r .cell-code}\n(high_per / low_per) / (high_neg / low_neg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.08276945\n```\n\n\n:::\n:::\n\n\n\nSimilarly to the odds ratio, the ratio between two odds ratios can be interpreted in the same way:\n\n- OR1 / OR2 > 1: the odds ratio for the numerator condition is x times higher than the odds ratio for the denominator condition\n- OR1 / OR2 < 1: the odds ratio for the numerator condition is x times lower than the odds ratio for the denominator condition\n\nOf course, the best way is using the `predict()` function:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- expand.grid(parenting = c(\"neglectful\", \"permissive\"),\n                     academic = c(\"low\", \"high\"))\npreds$pr <- predict(fit2_agg, newdata = preds)\n\nwith(preds, (exp(pr)[4] / exp(pr)[2]) / (exp(pr)[3] / exp(pr)[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.08276945\n```\n\n\n:::\n:::\n\n\n\nWhy the residual deviance is different between the aggregated and the binary model?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndeviance(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 384.5843\n```\n\n\n:::\n\n```{.r .cell-code}\ndeviance(fit2_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.664535e-15\n```\n\n\n:::\n:::\n\n\nThis is the main difference between the two approaches. Actually we do not have to compare the deviance of the two models e.g., the aggregated form is better because it is closer to 0 but we always need to compare the model with the null deviance.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(fit0, fit2, test = \"LRT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: drop ~ 1\nModel 2: drop ~ academic * parenting\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1       499     449.49                          \n2       492     384.58  7   64.902 1.573e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nanova(fit0_agg, fit2_agg, test = \"LRT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table\n\nModel 1: cbind(drop_1, drop_0) ~ 1\nModel 2: cbind(drop_1, drop_0) ~ academic * parenting\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1         7     64.902                          \n2         0      0.000  7   64.902 1.573e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\nAs you can see the ratio is the same, thus the two deviances are on a different scale. The two models explains the same amount of (relative) deviance.\n\nWhy?\n\nThe reason is that we are computing the residual deviance from observed 0 and 1 vs observed counts.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# aggregated model deviance\n-2*(sum(log(dbinom(dat_agg$drop_1, dat_agg$drop_tot, fitted(fit2_agg))) - log(dbinom(dat_agg$drop_1, dat_agg$drop_tot, dat_agg$drop_1/dat_agg$drop_tot))))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\n# binary model deviance\n-2*(sum(log(dbinom(dat$drop, 1, fitted(fit2))) - log(dbinom(dat$drop, 1, dat$drop))))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 384.5843\n```\n\n\n:::\n:::\n\n\n\nIn a way it is more difficult to predict 0 and 1 compared to counts thus the residuals and the residual deviance will be always higher. Model coefficients, standard error and tests are the same.\n\nWhere the two models are not the same? Depends on the type of variables. Let's add a new column to our binary dataset with the age of each student:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$age <- round(runif(nrow(dat), 12, 18))\n```\n:::\n\n\n\nNow, if we want to include the `age` as predictor, we need to use the binary form because we have one value for each student. We are including a predictor at the level of the 0-1 values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3 <- glm(drop ~ academic * parenting + age , data = dat, family = binomial(link = \"logit\"))\nsummary(fit3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = drop ~ academic * parenting + age, family = binomial(link = \"logit\"), \n    data = dat)\n\nCoefficients:\n                                    Estimate Std. Error z value Pr(>|z|)   \n(Intercept)                         -2.13525    1.18409  -1.803  0.07134 . \nacademichigh                        -0.36755    0.49826  -0.738  0.46072   \nparentingpermissive                 -0.93360    0.35826  -2.606  0.00916 **\nparentingauthoritative              -1.21584    0.66221  -1.836  0.06635 . \nparentingauthoritarian              -0.90124    0.43013  -2.095  0.03615 * \nage                                  0.10758    0.07618   1.412  0.15791   \nacademichigh:parentingpermissive    -2.49675    1.15915  -2.154  0.03124 * \nacademichigh:parentingauthoritative -1.12228    0.94987  -1.182  0.23740   \nacademichigh:parentingauthoritarian -0.07370    0.73001  -0.101  0.91958   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 449.49  on 499  degrees of freedom\nResidual deviance: 382.57  on 491  degrees of freedom\nAIC: 400.57\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n\nWhen we have predictors at the 0-1 levels, we need to use the binary form.\n\nA little (visual) demonstration:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(0, 1, 0.01)\ndat <- data.frame(\n    x = rep(x, 10)\n)\n\ndat$lp <- plogis(qlogis(0.01) + 8*dat$x)\ndat$y <- rbinom(nrow(dat), 1, dat$lp)\nhead(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     x         lp y\n1 0.00 0.01000000 0\n2 0.01 0.01082386 0\n3 0.02 0.01171478 0\n4 0.03 0.01267810 0\n5 0.04 0.01371954 0\n6 0.05 0.01484523 0\n```\n\n\n:::\n:::\n\n\n\nLet's fit the model in the binary form:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model prediction\nfit <- glm(y ~ x, data = dat, family = binomial())\n\n# equivalent to predict()\npi <- plogis(coef(fit)[1] + coef(fit)[2]*unique(dat$x))\n```\n:::\n\n\n\nLet's fit the mode in the binomial form:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# aggregated form\ndat_agg <- aggregate(y ~ x, FUN = sum, data = dat)\ndat_agg$n <- 10 # total trials\ndat_agg$f <- dat_agg$n - dat_agg$y\ndat_agg$p <- dat_agg$y / dat_agg$n\n\nhead(dat_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     x y  n  f   p\n1 0.00 0 10 10 0.0\n2 0.01 0 10 10 0.0\n3 0.02 0 10 10 0.0\n4 0.03 1 10  9 0.1\n5 0.04 0 10 10 0.0\n6 0.05 0 10 10 0.0\n```\n\n\n:::\n\n```{.r .cell-code}\nfit2 <- glm(cbind(y, f) ~ x, data = dat_agg, family = binomial())\npi <- plogis(coef(fit2)[1] + coef(fit2)[2]*dat_agg$x)\n```\n:::\n\n\n\nThe residuals (thus the residual deviance) will be always larger in the binary model (but the coefficients are the same):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1,2))\n\njit <- runif(nrow(dat), -0.03, 0.03)\nplot((y + jit) ~ x, data = dat, ylab = \"y\", xlab = \"x\",\n     main = \"Binary Form\")\nlines(unique(dat$x), pi, lwd = 2, col = \"red\")\n\nplot(y/n ~ x, data = dat_agg, ylab = \"y\",\n     main = \"Binomial Form\")\nlines(dat_agg$x, pi, lwd = 2, col = \"red\")\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-37-1.svg){width=672}\n:::\n:::\n\n\n\nThis is the reason why binary model have also strange residuals:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# also residuals\npar(mfrow = c(1,2))\nplot(fitted(fit), residuals(fit), main = \"Binary Form\")\nplot(fitted(fit2), residuals(fit2), main = \"Binomial Form\")\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-38-1.svg){width=672}\n:::\n:::\n",
    "supporting": [
      "lab3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}