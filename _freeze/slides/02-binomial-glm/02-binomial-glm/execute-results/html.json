{
  "hash": "0832f7348f9297ab71fa62cd286e8802",
  "result": {
    "markdown": "---\ntitle: Binomial GLM\ninstitute: \"University of Padova\"\nauthor: \n  - name: \"Filippo Gambarota\"\n    email: filippo.gambarota@unipd.it\n    twitter: fgambarota\n    github: filippogambarota\nformat:\n  quarto-slides-revealjs:\n    incremental: false\n    code-link: true\n    code-line-numbers: false\n    html-math-method: mathjax\n    filters:\n      - nutshell\n      - code-fullscreen\nfrom: markdown+emoji\ndate: last-modified\ndate-format: \"YYYY\"\nfinal-slide: false\ndf-print: tibble\nbibliography: \"https://raw.githubusercontent.com/filippogambarota/bib-database/main/references.bib\"\ncsl: \"https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\"\nupdated: \"*Last Update: 2023-11-29*\"\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n\n\n\n## Example: Passing the exam\n\nWe want to measure the impact of **watching tv-shows** on the probability of **passing the statistics exam**.\n\n- `exam`: **passing the exam** (1 = \"passed\", 0 = \"failed\")\n- `tv_shows`: **watching tv-shows regularly** (1 = \"yes\", 0 = \"no\")\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 2\n#>   tv_shows exam \n#>   <chr>    <chr>\n#> 1 1        0    \n#> 2 1        0    \n#> 3 1        1    \n#> 4 1        1    \n#> 5 ...      ...  \n#> 6 0        0    \n#> 7 0        0    \n#> 8 0        1    \n#> 9 0        1\n```\n:::\n:::\n\n\n## Example: Passing the exam\n\nWe can create the **contingency table**\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nxtabs(~exam + tv_shows, data = dat) |> \n    addmargins()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>      tv_shows\n#> exam    0   1 Sum\n#>   0    35  22  57\n#>   1    15  28  43\n#>   Sum  50  50 100\n```\n:::\n:::\n\n\n## Example: Passing the exam\n\nEach cell probability $p_{ij}$ is computed as $p_{ij}/n$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(xtabs(~exam + tv_shows, data = dat)/n) |> \n    addmargins()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>      tv_shows\n#> exam     0    1  Sum\n#>   0   0.35 0.22 0.57\n#>   1   0.15 0.28 0.43\n#>   Sum 0.50 0.50 1.00\n```\n:::\n:::\n\n\n## Example: Passing the exam - Odds\n\nThe most common way to analyze a 2x2 contingency table is using the **odds ratio** (OR). Firsly let's define *the odds of success* as:\n\n\\begin{align*}\nodds = \\frac{p}{1 - p} \\\\\np = \\frac{odds}{odds + 1}\n\\end{align*}\n\n- the **odds** are non-negative, ranging between 0 and $+\\infty$\n- an **odds** of e.g. 3 means that we expect 3 *success* for each *failure*\n\n## Example: Passing the exam - Odds\n\nFor the `exam` example:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nodds <- function(p) p / (1 - p)\np11 <- mean(with(dat, exam[tv_shows == 1])) # passing exam | tv_shows\np11\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.56\n```\n:::\n\n```{.r .cell-code}\nodds(p11)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 1.272727\n```\n:::\n:::\n\n\n## Example: Passing the exam - Odds Ratio\n\nThe OR is a ratio of odds:\n\n$$\nOR = \\frac{\\frac{p_1}{1 - p_1}}{\\frac{p_2}{1 - p_2}}\n$$\n\n- OR ranges between 0 and $+\\infty$. When $OR = 1$ the odds for the two conditions are equal\n- An e.g. $OR = 3$ means that being in the condition at the numerator increase 3 times the odds of success\n\n## Example: Passing the exam - Odds Ratio\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nodds_ratio <- function(p1, p2) odds(p1) / odds(p2)\np11 <- mean(with(dat, exam[tv_shows == 1])) # passing exam | tv_shows\np10 <- mean(with(dat, exam[tv_shows == 0])) # passing exam | not tv_shows\np11\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.56\n```\n:::\n\n```{.r .cell-code}\np10\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.3\n```\n:::\n\n```{.r .cell-code}\nodds_ratio(p11, p10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 2.969697\n```\n:::\n:::\n\n\n## Why using these measure?\n\nThe odds have an interesting property when taking the logarithm. We can express a probability $p$ using a scale ranging $[-\\infty, +\\infty]$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-10-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Another example, **Teddy Child**\n\nWe considered a Study conducted by the University of Padua (TEDDY Child\nStudy, 2020)^[Thanks to Prof. Paolo Girardi for the example, see https://teddychild.dpss.psy.unipd.it/ for information]. Within the study, researchers asked the participants (mothers of a young child) about the presence of post-partum depression and measured the parental stress using the PSI-Parenting Stress Index.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n```{=html}\n<div id=\"wkvvvrhnhu\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#wkvvvrhnhu table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#wkvvvrhnhu thead, #wkvvvrhnhu tbody, #wkvvvrhnhu tfoot, #wkvvvrhnhu tr, #wkvvvrhnhu td, #wkvvvrhnhu th {\n  border-style: none;\n}\n\n#wkvvvrhnhu p {\n  margin: 0;\n  padding: 0;\n}\n\n#wkvvvrhnhu .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#wkvvvrhnhu .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#wkvvvrhnhu .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#wkvvvrhnhu .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#wkvvvrhnhu .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#wkvvvrhnhu .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#wkvvvrhnhu .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#wkvvvrhnhu .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#wkvvvrhnhu .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#wkvvvrhnhu .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#wkvvvrhnhu .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wkvvvrhnhu .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#wkvvvrhnhu .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#wkvvvrhnhu .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#wkvvvrhnhu .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wkvvvrhnhu .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#wkvvvrhnhu .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#wkvvvrhnhu .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#wkvvvrhnhu .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wkvvvrhnhu .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#wkvvvrhnhu .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wkvvvrhnhu .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#wkvvvrhnhu .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wkvvvrhnhu .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wkvvvrhnhu .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wkvvvrhnhu .gt_left {\n  text-align: left;\n}\n\n#wkvvvrhnhu .gt_center {\n  text-align: center;\n}\n\n#wkvvvrhnhu .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#wkvvvrhnhu .gt_font_normal {\n  font-weight: normal;\n}\n\n#wkvvvrhnhu .gt_font_bold {\n  font-weight: bold;\n}\n\n#wkvvvrhnhu .gt_font_italic {\n  font-style: italic;\n}\n\n#wkvvvrhnhu .gt_super {\n  font-size: 65%;\n}\n\n#wkvvvrhnhu .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#wkvvvrhnhu .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#wkvvvrhnhu .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#wkvvvrhnhu .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#wkvvvrhnhu .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#wkvvvrhnhu .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#wkvvvrhnhu .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" style=\"font-weight: bold;\" scope=\"col\" id=\"ID\">ID</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" style=\"font-weight: bold;\" scope=\"col\" id=\"Parental_stress\">Parental_stress</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" style=\"font-weight: bold;\" scope=\"col\" id=\"Depression_pp\">Depression_pp</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">1</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">75</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">No</td></tr>\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">2</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">51</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">No</td></tr>\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">3</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">76</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">No</td></tr>\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">4</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">88</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">No</td></tr>\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">...</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">...</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">...</td></tr>\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">376</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">67</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">No</td></tr>\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">377</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">71</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">No</td></tr>\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">378</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">63</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">No</td></tr>\n    <tr><td headers=\"ID\" class=\"gt_row gt_center\">379</td>\n<td headers=\"Parental_stress\" class=\"gt_row gt_center\">70</td>\n<td headers=\"Depression_pp\" class=\"gt_row gt_center\">No</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n## Another example, **Teddy Child**\n\nWe want to see if the parental stress increase the probability of having post-partum depression:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-12-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Another example, **Teddy Child**\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-13-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Another example, **Teddy Child**\n\nLet's start by fitting a linear model `Depression_pp ~ Parental_stress`. We consider \"Yes\" as 1 and \"No\" as 0.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_lm <- lm(Depression_pp01 ~ Parental_stress, data = teddy)\nsummary(fit_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> lm(formula = Depression_pp01 ~ Parental_stress, data = teddy)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -0.42473 -0.13768 -0.10003 -0.05768  0.94702 \n#> \n#> Coefficients:\n#>                  Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)     -0.172900   0.077561  -2.229 0.026389 *  \n#> Parental_stress  0.004706   0.001201   3.919 0.000105 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 0.3239 on 377 degrees of freedom\n#> Multiple R-squared:  0.03915,\tAdjusted R-squared:  0.0366 \n#> F-statistic: 15.36 on 1 and 377 DF,  p-value: 0.0001054\n```\n:::\n:::\n\n\n## Another example, **Teddy Child**\n\nLet's add the fitted line to our plot:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-15-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Another example, **Teddy Child**\n\n... and check the residuals, pretty bad right?\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-16-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Another example, **Teddy Child**\n\nAs for the exam example, we could compute a sort of contingency table despite the `Parental_stress` is a numerical variable by creating some discrete categories (just for exploratory analysis):\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n::: columns\n:::: column\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(teddy$Depression_pp, teddy$Parental_stress_c) |> \n    round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>      \n#>       < 40 40-60 60-80 80-100 > 100\n#>   No     0   164   136     26     6\n#>   Yes    0    15    21      7     4\n```\n:::\n:::\n\n\n::::\n:::: column\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(teddy$Depression_pp, teddy$Parental_stress_c) |> \n    prop.table(margin = 2) |> \n    round(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>      \n#>       < 40 40-60 60-80 80-100 > 100\n#>   No        0.92  0.87   0.79  0.60\n#>   Yes       0.08  0.13   0.21  0.40\n```\n:::\n:::\n\n\n::::\n:::\n\n## Another example, **Teddy Child**\n\nIdeally, we could compute the increase in the odds of having the post-partum depression as the parental stress increase. In fact, as we are going to see, the Binomial GLM is able to estimate the non-linear increase in the probability.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-20-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Binomial GLM\n\n- The **random component** of a Binomial GLM the binomial distribution with parameter $p$\n- The **systematic component** is a linear combination of predictors and coefficients $\\boldsymbol{\\beta X}$\n- The **link function** is a function that map probabilities into the $[-\\infty, +\\infty]$ range.\n\n## Logit Link\n\nThe **logit** link is the most common link function when using a binomial GLM:\n\n$$\nlog \\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_{1}X_{1} + ...\\beta_pX_p  \n$$\n\nThe inverse of the **logit** maps again the probability into the $[0, 1]$ range:\n\n$$\np = \\frac{e^{\\beta_0 + \\beta_{1}X_{1} + ...\\beta_pX_p}}{1 + e^{\\beta_0 + \\beta_{1}X_{1} + ...\\beta_pX_p}}  \n$$\n\n## Logit Link\n\nThus with a single numerical predictor $x$ the relationship between $x$ and $p$ in non-linear on the probability scale but linear on the logit scale.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-21-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Logit Link\n\nThe problem is that effects are non-linear, thus is more difficult to interpret and report model results\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-22-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Model fitting in R\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/glm-fitting-R.png){fig-align='center' width=480}\n:::\n:::\n\n\n## The big picture...\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/big-picture.png){fig-align='center' width=388}\n:::\n:::\n\n\n\n## Model fitting in R\n\nWe can model the contingency table presented before. We put data in **binary form**:\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n::: columns\n:::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n#>     tv_shows\n#> exam  0  1\n#>    0 35 22\n#>    1 15 28\n```\n:::\n:::\n\n::::\n:::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 2\n#>   tv_shows exam \n#>   <chr>    <chr>\n#> 1 1        0    \n#> 2 1        1    \n#> 3 1        1    \n#> 4 1        1    \n#> 5 ...      ...  \n#> 6 0        0    \n#> 7 0        1    \n#> 8 0        0    \n#> 9 0        0\n```\n:::\n:::\n\n::::\n:::\n\n## Intercept only model\n\nLet's start from the simplest model (often called null model) where there are no predictors:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit0 <- glm(exam ~ 1, data = dat, family = binomial(link = \"logit\"))\nsummary(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> glm(formula = exam ~ 1, family = binomial(link = \"logit\"), data = dat)\n#> \n#> Deviance Residuals: \n#>    Min      1Q  Median      3Q     Max  \n#> -1.060  -1.060  -1.060   1.299   1.299  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)  -0.2819     0.2020  -1.395    0.163\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 136.66  on 99  degrees of freedom\n#> Residual deviance: 136.66  on 99  degrees of freedom\n#> AIC: 138.66\n#> \n#> Number of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n## Intercept only model\n\nWhen fitting an intercept-only model, the parameter is the average value of the `y` variable:\n\n\\begin{align*}\n\\log(\\frac{p}{1 - p}) = \\beta_0 \\\\\np = \\frac{e^{\\beta_0}}{1 + e^{\\beta_0}}\n\\end{align*}\n\n## Intercept only model\n\nIn R, the $logit(p)$ is computed using `qlogis()` that is the `q` + `logis` combination of functions to work with probability distributions. The $logit^{-1}$ thus the inverse of the logit function is `plogis()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# average y on the respo nse scale\nmean(dat$exam)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.43\n```\n:::\n\n```{.r .cell-code}\nc(\"logit\" = coef(fit0)[1],\n  \"inv-logit\" = plogis(coef(fit0)[1])\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     logit.(Intercept) inv-logit.(Intercept) \n#>            -0.2818512             0.4300000\n```\n:::\n:::\n\n\n## Link function (TIPS)\n\nIf you are not sure about how to transform using the link function you can directly access the `family()` object in R that contains the appropriate link function and the corresponding inverse.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbin <- binomial(link = \"logit\")\nbin$linkfun() # the same as qlogis\nbin$linkinv() # the same as plogis\n```\n:::\n\n\n## Model with $X$\n\nNow we can add the `tv_shows` predictor. Now the model has two coefficients. Given that the `tv_shows` is a binary variable, the intercept is the average `y` when `tv_shows` is 0, and the `tv_shows` coefficient is the increase in `y` for a unit increase in `tv_shows`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- glm(exam ~ tv_shows, data = dat, family = binomial(link = \"logit\"))\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> glm(formula = exam ~ tv_shows, family = binomial(link = \"logit\"), \n#>     data = dat)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -1.2814  -0.8446  -0.8446   1.0769   1.5518  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)   \n#> (Intercept)  -0.8473     0.3086  -2.746  0.00604 **\n#> tv_shows      1.0885     0.4200   2.592  0.00956 **\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 136.66  on 99  degrees of freedom\n#> Residual deviance: 129.68  on 98  degrees of freedom\n#> AIC: 133.68\n#> \n#> Number of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n## Model with $X$\n\nThinking about our data, the `(Intercept)` is the probability of passing the exam without watching tv-shows. The `tv_shows` (should be) the difference in the probability of passing the exam between people who watched or did not watched tv-shows, BUT:\n\n- we are on the logit scale. Thus we are modelling **log(odds)** and not probabilities\n- a difference on the **log** scale is a ratio on the raw scale. Thus taking the exponential of `tv_shows` we obtain the ratio of odds of passing the exam watching vs non-watching tv-shows. Do you remember something?\n\n## Model with $X$\n\nThe `tv_shows` is exactly the Odds Ratio that we calculated on the contingency table:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# from model coefficients\nexp(coef(fit)[\"tv_shows\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> tv_shows \n#> 2.969697\n```\n:::\n\n```{.r .cell-code}\n# from the contingency table\nodds_ratio(mean(dat$exam[dat$tv_shows == 1]),\n           mean(dat$exam[dat$tv_shows == 0]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 2.969697\n```\n:::\n:::\n\n\n# Parameter Intepretation {.section}\n\n## Model Intepretation\n\nGiven the non-linearity and the link function, parameter intepretation is not easy for GLMs. In the case of the Binomial GLM we will see:\n\n- interpreting model coefficients on the linear and logit scale\n- odds ratio (already introduced)\n- the divide by 4 rule [@Gelman2020-tg; @Gelman2006-pc]\n- marginal effects\n- predicted probabilities\n\n## Intepreting model coefficients\n\nModels coefficients are interpreted in the same way as standard regression models. The big difference concerns:\n\n- numerical predictors\n- categorical predictors\n\nUsing **contrast coding** and **centering/standardizing** we can make model coefficients easier to intepret.\n\n## Categorical predictors\n\nWe use a categorical predictor with $p$ levels, the model will estimate $p - 1$ parameters. The interpretation of these parameters is controlled by the contrast coding. In R the default is the treatment coding (or dummy coding). Essentially R create $p - 1$ dummy variables (0 and 1) where 0 is the reference level (usually the first category) and 1 is the current level. We can see the coding scheme using the `model.matrix()` function that return the $\\boldsymbol{X}$ matrix:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 2\n#>   X.Intercept. tv_shows\n#>   <chr>        <chr>   \n#> 1 1            1       \n#> 2 1            1       \n#> 3 1            1       \n#> 4 1            1       \n#> 5 ...          ...     \n#> 6 1            0       \n#> 7 1            0       \n#> 8 1            0       \n#> 9 1            0\n```\n:::\n:::\n\n\n## Categorical predictors\n\nIn the simple case of the `exam` dataset, the intercept ($\\beta_0$) is the reference level (default to 0 because is the first) and $\\beta_0$ is the difference between the actual level and the reference level. If we change the order of the levels we could change the intercept value while $\\beta_1$ will be the same. As an example we could use the so-called sum to zero coding where instead of assigning 0 and 1 we use different values. For example assigning -0.5 and 0.5 will make the intercept the grand-mean:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat$tv_shows0 <- ifelse(dat$tv_shows == 0, -0.5, 0.5)\nfit <- glm(exam ~ tv_shows0, data = dat, family = binomial(link = \"logit\"))\n# grand mean\nmean(c(mean(dat$exam[dat$tv_shows == 1]), mean(dat$exam[dat$tv_shows == 0])))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.43\n```\n:::\n\n```{.r .cell-code}\n# intercept\nplogis(coef(fit)[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> (Intercept) \n#>   0.4248077\n```\n:::\n:::\n\n\n## Categorical predictors\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-34-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Numerical predictors\n\nWith numerical predictors the idea is the same as categorical predictors. In fact, categorical predictors are converted into numbers (i.e., 0 and 1 or -0.5 and 0.5). The only caveat is that the effects are linear only the **logit** scale. Thus $\\beta_1$ is interpreted in the same way as standard linear models only on the link-function scale. For the **binomial** \n\nGLM the $\\beta_1$ is the increase in the $log(odds(p))$ for a unit-increase in the $x$. In the response (probability) scale, the $\\beta_1$ is the multiplicative increase in the odds of $y = 1$ for a unit increase in the predictor.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-35-1.svg){fig-align='center' width=50%}\n:::\n:::\n\n\n## Numerical predictors\n\nWith numerical predictors we could mean-center and or standardize the predictors. With centering (similarly to the categorical example) we change the interpretation of the intercept. Standardizing is helpful to have more meaningful $\\beta$ values. The $\\beta_i$ of a centered predictor is the increase in $y$ for a increase in one standard deviation of $x$.\n\n$$\nx_{cen} = x_i - \\hat x\n$$\n\n$$\nx_{z} = \\frac{x_i - \\hat x}{\\sigma_x}\n$$\n\n## Numerical predictors\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-36-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Numerical predictors\n\nLet's return to our teddy child example and fitting the proper model:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_glm <- glm(Depression_pp01 ~ Parental_stress, data = teddy, family = binomial(link = \"logit\"))\nsummary(fit_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> glm(formula = Depression_pp01 ~ Parental_stress, family = binomial(link = \"logit\"), \n#>     data = teddy)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -1.2852  -0.5165  -0.4509  -0.3861   2.3096  \n#> \n#> Coefficients:\n#>                  Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)     -4.323906   0.690689  -6.260 3.84e-10 ***\n#> Parental_stress  0.036015   0.009838   3.661 0.000251 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 284.13  on 378  degrees of freedom\n#> Residual deviance: 271.23  on 377  degrees of freedom\n#> AIC: 275.23\n#> \n#> Number of Fisher Scoring iterations: 5\n```\n:::\n:::\n\n\n## Numerical predictors\n\nThe `(Intercept)` ($\\beta_0$) is the probability of having post-partum depression for a mother with parental stress zero (maybe better centering?)\n\n$$\np(yes|x = 0) = g^{-1}(\\beta_0)\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplogis(coef(fit_glm)[\"(Intercept)\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> (Intercept) \n#>  0.01307482\n```\n:::\n:::\n\n\n## Numerical predictors\n\nThe `Parental_stress` ($\\beta_1$) is the increase in the $log(odds)$ of having the post-partum depression for a unit increase in the parental stress index. If we take the exponential of $\\beta_1$ we obtain the increase in the $odds$ of having post-partum depression for a unit increase in parental stress index.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp(coef(fit_glm)[\"Parental_stress\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Parental_stress \n#>        1.036671\n```\n:::\n:::\n\n\n## Numerical predictors\n\nThe problem is that, as shown before, the effects are non-linear on the probability scale while are linear on the logit scale. On the logit scale, all differences are constant:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npr <- list(c(10, 11), c(50, 51), c(70, 71))\n\npredictions <- lapply(pr, function(x) {\n    predict(fit_glm, newdata = data.frame(Parental_stress = x))\n})\n\n# notice that the difference is exactly the Parental_stress parameter\nsapply(predictions, diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>         2         2         2 \n#> 0.0360147 0.0360147 0.0360147\n```\n:::\n:::\n\n\n## Numerical predictors\n\nWhile on the probability scale, the differences are not the same. This is problematic when interpreting the results of a Binomial GLM with a numerical predictor.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(predictions <- lapply(predictions, plogis))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [[1]]\n#>          1          2 \n#> 0.01863764 0.01930790 \n#> \n#> [[2]]\n#>          1          2 \n#> 0.07424969 0.07676350 \n#> \n#> [[3]]\n#>         1         2 \n#> 0.1415012 0.1459330\n```\n:::\n\n```{.r .cell-code}\nsapply(predictions, diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>            2            2            2 \n#> 0.0006702661 0.0025138036 0.0044317558\n```\n:::\n:::\n\n\n## Divide by 4 rule\n\nThe **divide by 4 rule** is a very easy way to evaluate the effect of a continuous predictor.\n\nGiven the non-linearity, the derivative of the logistic function (i.e., the slope) is maximal for probabilities around ~$0.5$.\n\nIn fact, $\\beta_i p (1 - p)$ is maximized when $p = 0.5$ turning into $\\beta_i 0.25$ (i.e., dividing by 4).\n\nDividing $\\beta/4$ we obtain the maximal slope thus the maximal difference in probability.\n\n## Divide by 4 rule\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-42-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Predicted probabilities\n\nIn a similar way we can use the inverse logit function to find the predicted probability specific values of $x$. For example, the difference between $p(y = 1|x = 2.5) - p(y = 1|x = 5)$ can be calculated using the model equation:\n\n- $logit^{-1}p(y = 1|x = 2.5) = \\frac{e^{\\beta_0 + \\beta_1 2.5}}{1 + e^{\\beta_0 + \\beta_1 2.5}}$\n- $logit^{-1}p(y = 1|x = 5) = \\frac{e^{\\beta_0 + \\beta_1 5}}{1 + e^{\\beta_0 + \\beta_1 5}}$\n- $logit^{-1}p(y = 1|x = 5) - logit^{-1}p(y = 1|x = 2.5)$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncoefs <- coef(fit)\nplogis(coefs[1] + coefs[2]*5) - plogis(coefs[1] + coefs[2]*2.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> (Intercept) \n#>   0.2237369\n```\n:::\n:::\n\n\n## Predicted probabilities\n\nIn R we can use directly the `predict()` function with the argument `type = \"response\"` to return the predicted probabilities instead of the logits:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npreds <- predict(fit, newdata = list(x = c(2.5, 5)), type = \"response\")\npreds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>         1         2 \n#> 0.0329886 0.2567255\n```\n:::\n\n```{.r .cell-code}\npreds[2] - preds[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>         2 \n#> 0.2237369\n```\n:::\n:::\n\n\n## Predicted probabilities\n\nI have written the `epredict()` function that extend the `predict()` function giving some useful messages when computing predictions. you can use it with every model and also with multiple predictors.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nepredict(fit, values = list(x = c(2.5, 5)), type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> y ~ -5.693 + 0.926*c(2.5, 5)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.0329886 0.2567255\n```\n:::\n:::\n\n\n## Marginal effects\n\nA marginal effect measures the association between a change in a predictor ($x$), and a change in the response $y$.\n\nThe slope can be evaluated for any level of $x$. In fact, the divide-by-4 rule is the maximal slope evaluated at a specific $x$.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-46-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Marginal effects\n\nThe divide-by-4 rule is the maximal marginal effect. The average marginal effects is the average of all slopes. This can be easily done with the `marginaleffects` package:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(marginaleffects)\n\n# all marginal effects\nslopes(fit)\n#> # A tibble: 100 × 14\n#>    rowid term  estimate std.error statistic   p.value s.value conf.low conf.high\n#>    <int> <chr>    <dbl>     <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n#>  1     1 x      0.00403   0.00354      1.14   2.55e-1    1.97 -2.91e-3   0.0110 \n#>  2     2 x      0.137     0.0277       4.95   7.47e-7   20.4   8.28e-2   0.191  \n#>  3     3 x      0.0489    0.0213       2.30   2.15e-2    5.54  7.23e-3   0.0906 \n#>  4     4 x      0.0383    0.0188       2.04   4.15e-2    4.59  1.48e-3   0.0750 \n#>  5     5 x      0.222     0.0407       5.45   4.91e-8   24.3   1.42e-1   0.302  \n#>  6     6 x      0.0526    0.0193       2.72   6.48e-3    7.27  1.47e-2   0.0905 \n#>  7     7 x      0.0811    0.0229       3.54   3.98e-4   11.3   3.62e-2   0.126  \n#>  8     8 x      0.199     0.0386       5.16   2.52e-7   21.9   1.23e-1   0.275  \n#>  9     9 x      0.00353   0.00319      1.11   2.68e-1    1.90 -2.72e-3   0.00979\n#> 10    10 x      0.0270    0.0136       1.99   4.68e-2    4.42  3.82e-4   0.0537 \n#> # ℹ 90 more rows\n#> # ℹ 5 more variables: predicted_lo <dbl>, predicted_hi <dbl>, predicted <dbl>,\n#> #   y <int>, x <dbl>\n```\n:::\n\n\n## Marginal effects\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# marginal effects when x = 5\nslopes(fit, newdata = data.frame(x = 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 1 × 14\n#>   rowid term  estimate std.error statistic    p.value s.value conf.low conf.high\n#>   <int> <chr>    <dbl>     <dbl>     <dbl>      <dbl>   <dbl>    <dbl>     <dbl>\n#> 1     1 x        0.177    0.0338      5.22    1.76e-7    22.4    0.110     0.243\n#> # ℹ 5 more variables: predicted_lo <dbl>, predicted_hi <dbl>, predicted <dbl>,\n#> #   x <dbl>, y <int>\n```\n:::\n\n```{.r .cell-code}\n# average marginal effect\navg_slopes(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 1 × 8\n#>   term  estimate std.error statistic   p.value s.value conf.low conf.high\n#>   <chr>    <dbl>     <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n#> 1 x       0.0934   0.00312      29.9 5.94e-197    652.   0.0873    0.0995\n```\n:::\n:::\n\n\n## Marginal effects\n\nWith multiple variables, marginal effects are also useful to see the effect of one predictor fixing the level of others. Let's simulate a model with two predictors:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- sim_design(100, nx = list(x1 = runif(100), x2 = runif(100)))\ndat <- sim_data(dat, plogis(qlogis(0.001) + 5 * x1 + 2 * x2), model = \"binomial\")\nfit <- glm(y ~ x1 + x2, data = dat, family = binomial(link = \"logit\"))\nplot(ggeffect(fit)$x1) | plot(ggeffect(fit)$x2)\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-49-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Marginal effects\n\nWe can see the marginal effects (each, average or marginal) for the $x1$ while fixing $x2$ to the mean:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nslopes(fit, newdata = data.frame(x1 = dat$x1, x2 = mean(dat$x2)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 200 × 15\n#>    rowid term  estimate std.error statistic p.value s.value conf.low conf.high\n#>    <int> <chr>    <dbl>     <dbl>     <dbl>   <dbl>   <dbl>    <dbl>     <dbl>\n#>  1     1 x1      0.0991    0.0624     1.59   0.112     3.16 -0.0232     0.221 \n#>  2     2 x1      0.191     0.195      0.979  0.327     1.61 -0.191      0.573 \n#>  3     3 x1      0.0805    0.0419     1.92   0.0546    4.20 -0.00157    0.163 \n#>  4     4 x1      0.0555    0.0227     2.45   0.0145    6.11  0.0110     0.100 \n#>  5     5 x1      0.0499    0.0204     2.45   0.0145    6.11  0.00990    0.0899\n#>  6     6 x1      0.0998    0.0632     1.58   0.114     3.13 -0.0241     0.224 \n#>  7     7 x1      0.135     0.110      1.23   0.219     2.19 -0.0803     0.350 \n#>  8     8 x1      0.0605    0.0254     2.38   0.0174    5.84  0.0106     0.110 \n#>  9     9 x1      0.220     0.241      0.913  0.361     1.47 -0.252      0.691 \n#> 10    10 x1      0.152     0.134      1.13   0.258     1.95 -0.111      0.414 \n#> # ℹ 190 more rows\n#> # ℹ 6 more variables: predicted_lo <dbl>, predicted_hi <dbl>, predicted <dbl>,\n#> #   x1 <dbl>, x2 <dbl>, y <int>\n```\n:::\n:::\n\n\n## Inverse estimation^[see also the [`investr`](https://cran.r-project.org/web/packages/investr/vignettes/introduction.pdf) package]\n\nSometimes it is useful to do what is called **inverse estimation**, thus predicting the $x$ level associated with a certain $y$. In this case the $x$ producing a certain $p$ of response.\n\nSometimes this is called **median effective dose** when finding the $x$ level producing $50\\%$ of correct responses.\n\nWe can use the `MASS::dose.p()` function:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nMASS::dose.p(fit, p = c(0.25, 0.5, 0.8))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>               Dose       SE\n#> p = 0.25: 2.301454 1.318885\n#> p = 0.50: 2.917503 1.732353\n#> p = 0.80: 3.694871 2.271767\n```\n:::\n:::\n\n\n## Inverse estimation and Psychophysics\n\nIn Psychophysics it is common to do the inverse estimation to estimate the detection or performance threshold. For example, estimating the $x$ level associated with a certain probability of success e.g. 50%.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ncurve(plogis(x, 0.7, 1/8), \n      ylim = c(0, 1),\n      xlab = \"Stimulus Contrast\",\n      ylab = \"Probability of Detection\",\n      lwd = 2)\nsegments(x0 = 0.7, y0 = 0, x1 = 0.7, 0.5, lty = 2)\nsegments(x0 = 0, y0 = 0.5, x1 = 0.7, 0.5, lty = 2)\npoints(x = 0.7, y = 0.5, pch = 19, col = \"firebrick\", cex = 2)\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-52-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Inverse estimation and Psychophysics\n\nLet's simulate and ideal observer that respond to stimuli with different contrast:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nth <- 0.7 # -(b0/b1)\nslope <- 1/8\n\nb1 <- 1/slope\nb0 <- -th*b1\n\nx <- rep(seq(0, 1, 0.1), each = 20)\n\np <- plogis(b0 + b1 * x)\ny <- rbinom(length(x), 1, p)\n\nyp <- tapply(y, x, mean)\nxc <- unique(x)\n\nplot(xc, yp, type = \"b\", ylim = c(0, 1), xlab = \"Contrast\", ylab = \"Probability of Detection\")\ncurve(plogis(x, th, slope), add = TRUE, col = \"firebrick\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-53-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Inverse estimation and Psychophysics\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- glm(y ~ x, family = binomial(link = \"logit\"))\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> glm(formula = y ~ x, family = binomial(link = \"logit\"))\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -2.0471  -0.6306  -0.2320   0.5124   2.6938  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)  -4.9927     0.6644  -7.515 5.69e-14 ***\n#> x             6.9569     0.9410   7.393 1.44e-13 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 273.67  on 219  degrees of freedom\n#> Residual deviance: 163.71  on 218  degrees of freedom\n#> AIC: 167.71\n#> \n#> Number of Fisher Scoring iterations: 6\n```\n:::\n:::\n\n\n## Inverse estimation and Psychophysics\n\nWe can estimate the threshold and slope of the psychometric function using the equations from @Knoblauch2012-to.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n-(coef(fit)[1]/coef(fit)[2]) # threshold\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> (Intercept) \n#>   0.7176681\n```\n:::\n\n```{.r .cell-code}\nMASS::dose.p(fit, p = 0.5) # with inverse estimation\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>               Dose        SE\n#> p = 0.5: 0.7176681 0.0287526\n```\n:::\n:::\n\n\n## Odds Ratio (OR) to Cohen's $d$\n\nThe Odds Ratio can be considered an effect size measure. We can transform the OR into other effect size measure [@Sanchez-Meca2003-ji; @Borenstein2009-mo].\n\n$$\nd = \\log(OR) \\frac{\\sqrt{3}}{\\pi}\n$$\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# in R with the effectsize package\nor <- 1.5\neffectsize::logoddsratio_to_d(log(or))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.2235446\n```\n:::\n\n```{.r .cell-code}\n# or \neffectsize::oddsratio_to_d(or)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.2235446\n```\n:::\n:::\n\n\n## Odds Ratio (OR) to Cohen's $d$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-57-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n# Inference {.section}\n\n## Wald tests\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nThe basic approach when doing inference with GLM is interpreting the Wald test of each model coefficients. The Wald test is calculated as follows:\n\n$$\nz = \\frac{\\beta_i - \\beta_0}{\\sigma_{\\beta_i}}\n$$\n\nWhere $\\beta$ is the regression coefficients, $\\beta_0$ is the value under the null hypothesis (generally 0) and $\\sigma_{\\beta_i}$ is the standard error. P-values and confidence intervals can be calculated based on a standard normal distribution.\n\n## Wald-type confidence intervals\n\nWald-type confidence interval (directly from model summary), where $\\Phi$ is the cumulative Gaussian function `qnorm()`:\n\n$$\n95\\%CI = \\hat \\beta \\pm \\Phi(\\alpha/2) SE_{\\beta}  \n$$\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(summ <- data.frame(summary(fit)$coefficients))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 4\n#>   Estimate Std..Error z.value Pr...z..\n#>      <dbl>      <dbl>   <dbl>    <dbl>\n#> 1   -0.575      0.295   -1.95 0.0508  \n#> 2    1.42       0.427    3.33 0.000855\n```\n:::\n\n```{.r .cell-code}\n# 95% confidence interval\nsumm$Estimate + qnorm(c(0.025, 0.95))*summ$Std..Error\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] -1.152824  2.124464\n```\n:::\n:::\n\n\n## Profile likelihood confidence intervals\n\nThe computation is a little bit different and they are not always symmetric:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# profile likelihood, different from wald type\nconfint(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                  2.5 %      97.5 %\n#> (Intercept) -1.1726621 -0.00947434\n#> tv_shows     0.6034638  2.28247024\n```\n:::\n:::\n\n\n## Profile likelihood confidence intervals\n\nYou can use the `plot_param()` function (quite overkilled):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_param(fit, \"tv_shows\")\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-61-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Confidence intervals\n\nWhen calculating confidence intervals it is important to consider the link function. In the same way as we compute the inverse logit function on the parameter value, we could revert also the confidence intervals. **IMPORTANT, do not apply the inverse logit on the standard error and then compute the confidence interval**.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfits <- broom::tidy(fit) # extract parameters as dataframe\nfits\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 5\n#>   term        estimate std.error statistic   p.value\n#>   <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n#> 1 (Intercept)    -1.15     0.331     -3.48 0.000500 \n#> 2 tv_shows        1.73     0.443      3.90 0.0000967\n```\n:::\n:::\n\n\n## Confidence intervals^[Notice that I use `2*se` instead of the precise quantile of the Gaussian distribution that for $\\alpha = 0.05$ is $\\sim 1.96$]\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nb <- fits$estimate[2]\nse <- fits$std.error[2]\n\n# correct, wald-type confidence intervals\nc(b = exp(b), lower = exp(b - 2*se), upper = exp(b + 2*se))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>        b    lower    upper \n#>  5.62963  2.32003 13.66049\n```\n:::\n\n```{.r .cell-code}\n# correct, likelihood based confidence intervals\nexp(confint(fit, \"tv_shows\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     2.5 %    97.5 % \n#>  2.417513 13.850465\n```\n:::\n\n```{.r .cell-code}\n# wrong wald type\nc(b = exp(b), lower = exp(b) - 2*exp(se), upper = exp(b) + 2*exp(se))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>        b    lower    upper \n#> 5.629630 2.514163 8.745097\n```\n:::\n:::\n\n\n## Confidence intervals\n\nThe same principle holds for predicted probabilities. First compute the intervals on the logit scale and then transform-back on the probability scale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfits <- dat |> \n    select(tv_shows) |> \n    distinct() |> \n    add_predict(fit, se.fit = TRUE)\n\nfits$p <- plogis(fits$fit)\nfits$lower <- plogis(with(fits, fit - 2*se.fit))\nfits$upper <- plogis(with(fits, fit + 2*se.fit))\n\nfits\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 7\n#>   tv_shows    fit se.fit residual.scale     p lower upper\n#>      <dbl>  <dbl>  <dbl>          <dbl> <dbl> <dbl> <dbl>\n#> 1        1  0.575  0.295              1 0.640 0.497 0.762\n#> 2        0 -1.15   0.331              1 0.240 0.140 0.380\n```\n:::\n:::\n\n\n## Anova\n\nWith multiple predictors, especially with categorical variables with more than 2 levels, we can compute the an anova-like analysis individuating the effect of each predictor. In R we can do this using the `car::Anova()` function. Let's simulate a model with a 2x2 interaction:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 6 × 4\n#>      id x1    x2        y\n#>   <int> <fct> <fct> <int>\n#> 1     1 a     c         1\n#> 2     2 a     d         0\n#> 3     3 b     c         1\n#> 4     4 b     d         1\n#> 5     5 a     c         1\n#> 6     6 a     d         0\n```\n:::\n:::\n\n\n## Anova\n\nWe can fit the most complex model containing the two main effects and the interaction. I set the contrasts for the two factors as `contr.sum()/2` that are required for a proper analysis of factorial designs:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_max <- glm(y ~ x1 + x2 + x1:x2, data = dat, family = binomial(link = \"logit\")) # same as x1 * x2\nsummary(fit_max)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> glm(formula = y ~ x1 + x2 + x1:x2, family = binomial(link = \"logit\"), \n#>     data = dat)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -1.1213  -0.9005  -0.5350   1.2346   2.0074  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)  -0.8864     0.2138  -4.147 3.37e-05 ***\n#> x11           0.7921     0.4275   1.853   0.0639 .  \n#> x21           0.9462     0.4275   2.213   0.0269 *  \n#> x11:x21      -0.4649     0.8551  -0.544   0.5867    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 148.26  on 119  degrees of freedom\n#> Residual deviance: 139.86  on 116  degrees of freedom\n#> AIC: 147.86\n#> \n#> Number of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n## Anova\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(ggeffect(fit_max))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> $x1\n```\n:::\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-68-1.svg){fig-align='center' width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> $x2\n```\n:::\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-68-2.svg){fig-align='center' width=672}\n:::\n:::\n\n\n\n## Anova\n\nThen using `car::Anova()`. For each effect we have the $\\chi^2$ statistics and the associated p-value. The null hypothesis is that the specific factor did not contribute in reducing the residual deviance.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncar::Anova(fit_max)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 3 × 3\n#>   `LR Chisq`    Df `Pr(>Chisq)`\n#>        <dbl> <dbl>        <dbl>\n#> 1      3.32      1       0.0683\n#> 2      4.92      1       0.0266\n#> 3      0.299     1       0.584\n```\n:::\n:::\n\n\n## Model comparison\n\nThe table obtained with `car::Anova()` is essentially a model comparison using the Likelihood Ratio test. This can be done using the `anova(...)` function.\n\n\\begin{align*}\nD = 2 (log(\\mathcal{L}_{full}) - log(\\mathcal{L}_{reduced})) \\\\\nD \\sim \\chi^2_{df_{full} - df_{reduced}}\n\\end{align*}\n\n## Model comparison\n\nTo better understanding, the `x2` effect reported in the `car::Anova()` table is a model comparison between a model with `y ~ x1 + x2` and a model without `x2`. The difference between these two model is the unique contribution of `x2` after controlling for `x1`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- glm(y ~ x1 + x2, data = dat, family = binomial(link = \"logit\"))\nfit0 <- glm(y ~ x1, data = dat, family = binomial(link = \"logit\"))\n\nanova(fit0, fit, test = \"LRT\") # ~ same as car::Anova(fit_max)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 5\n#>   `Resid. Df` `Resid. Dev`    Df Deviance `Pr(>Chi)`\n#>         <dbl>        <dbl> <dbl>    <dbl>      <dbl>\n#> 1         118         145.    NA    NA       NA     \n#> 2         117         140.     1     4.92     0.0266\n```\n:::\n:::\n\n\n## Model comparison\n\nThe model comparison using `anova()` (i.e., likelihood ratio tests) is limited to nested models thus models that differs only for one term. For example:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit1 <- glm(y ~ x1, data = dat, family = binomial(link = \"logit\"))\nfit2 <- glm(y ~ x2, data = dat, family = binomial(link = \"logit\"))\nfit3 <- glm(y ~ x1 + x2, data = dat, family = binomial(link = \"logit\"))\n```\n:::\n\n\n`fit1` and `fit2` are non-nested because we have the same number of predictors (thus degrees of freedom). `fit3` and `fit1`/`fit2` are nested because `fit3` is more complex and removing one term we can obtain the less complex models.\n\n## Model comparison\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(fit1, fit2, test = \"LRT\") # do not works properly\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 5\n#>   `Resid. Df` `Resid. Dev`    Df Deviance `Pr(>Chi)`\n#>         <dbl>        <dbl> <dbl>    <dbl>      <dbl>\n#> 1         118         145.    NA    NA            NA\n#> 2         118         143.     0     1.59         NA\n```\n:::\n\n```{.r .cell-code}\nanova(fit1, fit3, test = \"LRT\") # same anova(fit2, fit3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 5\n#>   `Resid. Df` `Resid. Dev`    Df Deviance `Pr(>Chi)`\n#>         <dbl>        <dbl> <dbl>    <dbl>      <dbl>\n#> 1         118         145.    NA    NA       NA     \n#> 2         117         140.     1     4.92     0.0266\n```\n:::\n:::\n\n\n## Information Criteria\n\nAs for standard linear models I can use the Akaike Information Criteria (AIC) or the Bayesian Information Criteria (BIC) to compare non-nested models. The downside is not having a properly hypothesis testing setup.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata.frame(BIC(fit1, fit2, fit3)) |> \n    arrange(BIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 3 × 2\n#>      df   BIC\n#>   <dbl> <dbl>\n#> 1     2  153.\n#> 2     3  155.\n#> 3     2  155.\n```\n:::\n\n```{.r .cell-code}\ndata.frame(AIC(fit1, fit2, fit3)) |> \n    arrange(AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 3 × 2\n#>      df   AIC\n#>   <dbl> <dbl>\n#> 1     3  146.\n#> 2     2  147.\n#> 3     2  149.\n```\n:::\n:::\n\n\n## Marginal Means\n\nFor post-hoc contrasts you can use the `emmeans` package both for numerical but especially categorical predictors. Let's simulate a 2x2 interaction:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndat <- sim_design(100, cx = list(x1 = c(\"a\", \"b\"), x2 = c(\"c\", \"d\")), contrasts = contr.sum2)\ndat <- sim_data(dat, plogis(qlogis(0.25) + 0 * x1_c + 2 * x2_c + 2 * x1_c * x2_c))\nfit <- glm(y ~ x1 * x2, data = dat, family = binomial(link = \"logit\"))\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> glm(formula = y ~ x1 * x2, family = binomial(link = \"logit\"), \n#>     data = dat)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -1.5096  -0.6866  -0.2468   0.8782   2.6482  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)  -1.1449     0.1755  -6.524 6.86e-11 ***\n#> x11          -0.4326     0.3510  -1.232    0.218    \n#> x21           2.5113     0.3510   7.155 8.37e-13 ***\n#> x11:x21       3.4372     0.7020   4.896 9.76e-07 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 502.99  on 399  degrees of freedom\n#> Residual deviance: 386.90  on 396  degrees of freedom\n#> AIC: 394.9\n#> \n#> Number of Fisher Scoring iterations: 6\n```\n:::\n:::\n\n\n## Marginal Means\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(ggeffects::ggeffect(fit, terms = c(\"x1\", \"x2\")))\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-75-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Marginal Means\n\n`emmeans` is a very powerful and complicate package ([documentation]( https://cran.r-project.org/web/packages/emmeans/index.html)). Firstly we can estimate the marginal means of the conditions:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(emmeans)\nemmeans(fit, ~ x1 + x2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  x1 x2 emmean    SE  df asymp.LCL asymp.UCL\n#>  a  c   0.754 0.214 Inf     0.334     1.174\n#>  b  c  -0.532 0.207 Inf    -0.938    -0.126\n#>  a  d  -3.476 0.586 Inf    -4.625    -2.327\n#>  b  d  -1.325 0.246 Inf    -1.806    -0.844\n#> \n#> Results are given on the logit (not the response) scale. \n#> Confidence level used: 0.95\n```\n:::\n:::\n\n\n## Marginal Means\n\nWe can also calculate the marginal means on the response scale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(emmeans)\nemmeans(fit, ~ x1 + x2, type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  x1 x2 prob     SE  df asymp.LCL asymp.UCL\n#>  a  c  0.68 0.0466 Inf   0.58264    0.7639\n#>  b  c  0.37 0.0483 Inf   0.28127    0.4685\n#>  a  d  0.03 0.0171 Inf   0.00971    0.0889\n#>  b  d  0.21 0.0407 Inf   0.14111    0.3008\n#> \n#> Confidence level used: 0.95 \n#> Intervals are back-transformed from the logit scale\n```\n:::\n:::\n\n\n## Marginal Means\n\nCrucially we can compute the contrasts (i.e., the post-hoc tests). Notice that they are computed on the link-function scale:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemmeans(fit, pairwise ~ x1 | x2)$contrasts\n#> x2 = c:\n#>  contrast estimate    SE  df z.ratio p.value\n#>  a - b        1.29 0.298 Inf   4.314  <.0001\n#> \n#> x2 = d:\n#>  contrast estimate    SE  df z.ratio p.value\n#>  a - b       -2.15 0.636 Inf  -3.385  0.0007\n#> \n#> Results are given on the log odds ratio (not the response) scale.\nemmeans(fit, pairwise ~ x1 | x2, type = \"response\")$contrasts\n#> x2 = c:\n#>  contrast odds.ratio     SE  df null z.ratio p.value\n#>  a / b         3.618 1.0786 Inf    1   4.314  <.0001\n#> \n#> x2 = d:\n#>  contrast odds.ratio     SE  df null z.ratio p.value\n#>  a / b         0.116 0.0739 Inf    1  -3.385  0.0007\n#> \n#> Tests are performed on the log odds ratio scale\n```\n:::\n\n\n## Marginal Means\n\nNotice the order of the terms to change the actual type of contrasts:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemmeans(fit, pairwise ~ x2 | x1)$contrasts\n#> x1 = a:\n#>  contrast estimate    SE  df z.ratio p.value\n#>  c - d       4.230 0.624 Inf   6.777  <.0001\n#> \n#> x1 = b:\n#>  contrast estimate    SE  df z.ratio p.value\n#>  c - d       0.793 0.321 Inf   2.468  0.0136\n#> \n#> Results are given on the log odds ratio (not the response) scale.\nemmeans(fit, pairwise ~ x2 | x1, type = \"response\")$contrasts\n#> x1 = a:\n#>  contrast odds.ratio    SE  df null z.ratio p.value\n#>  c / d         68.71 42.89 Inf    1   6.777  <.0001\n#> \n#> x1 = b:\n#>  contrast odds.ratio    SE  df null z.ratio p.value\n#>  c / d          2.21  0.71 Inf    1   2.468  0.0136\n#> \n#> Tests are performed on the log odds ratio scale\n```\n:::\n\n\n# Plotting effects {.section}\n\n## Marginal effects\n\nWhen plotting a binomial GLM the most useful way is plotting the marginal probabilities and standard errors/confidence intervals for a given combination of predictors. Let's make an example for:\n\n- simple GLM with 1 categorical/numerical predictor\n- GLM with 2 numerical/categorical predictors\n- GLM with interaction between numerical and categorical predictors\n\n## Marginal effects\n\nA general workflow could be:\n\n- fit the model\n- use the `predict()` function giving the grid of values on which computing predictions\n- calculating the confidence intervals\n- plotting the results\n\nEverything can be simplified using some packages to perform each step and returning a plot:\n\n- `allEffects()` from the `effects()` package (return a base R plot)\n- `ggeffect()` from the `ggeffect()` package (return a `ggplot2` object)\n- `plot_model` from the `sjPlot` package (similar to `ggeffect()`)\n   \n## 1 categorical predictor\n\nIn this situation we can just plot the marginal probabilities for each level of the categorical predictor. Plotting our exam dataset:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-80-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## 1 numerical predictor\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-81-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## `allEffects()`\n\n::: columns\n:::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-82-1.svg){fig-align='center' width=672}\n:::\n:::\n\n::::\n:::: column\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-83-1.svg){fig-align='center' width=672}\n:::\n:::\n\n::::\n:::\n\n## `ggeffect()`/`plot_model()`\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-84-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Plotting coefficients\n\n::: columns\n:::: column\nSometimes could be useful to plot the estimated sampling distribution of a coefficient. For example, we can plot the `tv_shows` effect on our example. I've written the `plot_param()` function that directly create a basic-plot given the model and the coefficient name. The plot highlight the null value and the 95% Wald confidence interval.\n::::\n:::: column\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-85-1.svg){fig-align='center' width=672}\n:::\n:::\n\n::::\n:::\n\n# GLM - Diagnostic {.section}\n\n## GLM - Diagnostic\n\nThe diagnostic for GLM is similar to standard linear models. Some areas are more complicated for example residual analysis and goodness of fit. We will see:\n\n- Deviance\n- $R^2$\n- Residuals\n  - Types of residuals\n  - Residual deviance\n- Classification accuracy\n- Outliers and influential observations\n\n## Likelihood\n\nThe likelihood is the joint probability of the observed data viewed as a function of the parameters.\n\n$$\n\\log \\mathcal{L}(\\mu|x) = \\sum^n_{i = 1} \\log(\\mu|x_i)\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- rnorm(10) # data from normal distribution\n\n# data\nx\n#>  [1] -1.8694218  0.1218114 -1.3832446  0.9884026 -0.4416857 -0.3099413\n#>  [7] -0.8407464 -1.8613016  0.2581889 -0.1618937\n\n# the model is a normal distribution with mu = 0 and sd = 1\ndnorm(x, 0, 1)\n#>  [1] 0.06950842 0.39599347 0.15325971 0.24477683 0.36186586 0.38023327\n#>  [7] 0.28016802 0.07056927 0.38586439 0.39374833\n\n# log likelihood\nsum(log(dnorm(x, 0, 1)))\n#> [1] -14.66699\n```\n:::\n\n\n## Likelihood\n\nBy summing the logarithm all the red segments we obtain the log likelihood of the model given the observed data.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-87-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Likelihood\n\nIn the previous slide we tried only 3 values for the mean. Let's image to calculate the log likelihood for several different means. The parameter with that is associated with highest likelihood is called the maximum likelihood estimator. In fact, the $\\mu = 0$ is associated with the highest likelihood.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-88-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Deviance\n\nThe (residual) deviance in the context of GLM can be considered as the distance between the current model and a perfect model (often called *saturated model*).\n\n$$\nD_{res} = -2[\\log(\\mathcal{L}_{current}) - (\\log\\mathcal{L}_{sat})]\n$$\n\nWhere $\\mathcal{L}$ is the likelihood of the considered model (see the previous slides). Clearly, the lower the deviance, the closer the current model to the perfect model suggesting a good fit.\n\n## Deviance - Saturated model\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nThe saturated model is a model where each observation $x_i$ has a parameter.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-90-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Deviance - Null model\n\nAnother important quantity is the *null deviance* that is expressed as the distance between the *null model* and the *saturated model*.\n\n$$\nD_{null} = -2[\\log(\\mathcal{L}_{null}) - (\\log\\mathcal{L}_{sat})]\n$$\n\nThe *null deviance* can be interpreted as the maximal deviance because is estimated using a model without predictors. A good model will have a residual deviance lower than the null model.\n\n## Deviance - Null model\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-91-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Deviance - Likelihood Ratio Test\n\nWhen we perform a likelihood ratio test (see previous slides) we are essentially comparing the residual deviance (or the likelihood) of two models.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_null <- glm(y ~ 1, data = dat, family = binomial(link = \"logit\"))\nfit_current <- glm(y ~ x, data = dat, family = binomial(link = \"logit\"))\n```\n:::\n\n\n## Deviance - Likelihood Ratio Test\n\nWith the null model clearly the residual deviance is the same as the null deviance because we are not using predictors to reduce the deviance.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit_null)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> glm(formula = y ~ 1, family = binomial(link = \"logit\"), data = dat)\n#> \n#> Deviance Residuals: \n#>    Min      1Q  Median      3Q     Max  \n#> -1.044  -1.044  -1.044   1.317   1.317  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)\n#> (Intercept)  -0.3228     0.2865  -1.126     0.26\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 68.029  on 49  degrees of freedom\n#> Residual deviance: 68.029  on 49  degrees of freedom\n#> AIC: 70.029\n#> \n#> Number of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n## Deviance - Likelihood Ratio Test\n\nIf the predictor `x` is useful in explaining `y` the residual deviance will be reduced compared to the null (overall deviance).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(fit_current)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> glm(formula = y ~ x, family = binomial(link = \"logit\"), data = dat)\n#> \n#> Deviance Residuals: \n#>     Min       1Q   Median       3Q      Max  \n#> -2.9121  -0.4071  -0.2063   0.6259   1.7336  \n#> \n#> Coefficients:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)   -5.045      1.470  -3.432 0.000599 ***\n#> x              9.535      2.659   3.586 0.000336 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 68.029  on 49  degrees of freedom\n#> Residual deviance: 36.745  on 48  degrees of freedom\n#> AIC: 40.745\n#> \n#> Number of Fisher Scoring iterations: 6\n```\n:::\n:::\n\n\n## Deviance - Likelihood Ratio Test\n\nComparing the two models we can understand if the deviance reduction can be considered statistically significant.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(fit_null, fit_current, test = \"LRT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 5\n#>   `Resid. Df` `Resid. Dev`    Df Deviance    `Pr(>Chi)`\n#>         <dbl>        <dbl> <dbl>    <dbl>         <dbl>\n#> 1          49         68.0    NA     NA   NA           \n#> 2          48         36.7     1     31.3  0.0000000223\n```\n:::\n:::\n\n\nNotice that the difference between the two residual deviances is the test statistics that is distributed as a $\\chi^2$ with $df = 1$.\n\n## Deviance - Likelihood Ratio Test\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](img/lrt.svg){fig-align='center'}\n:::\n:::\n\n\n## Deviance^[Adapted from https://bookdown.org/egarpor/SSS2-UC3M/logreg-deviance.html]\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-98-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Deviance - Example \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nLet's fit the three models:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# null\nfit0 <- glm(exam ~ 1, data = dat, family = binomial(link = \"logit\"))\n# current\nfit <- glm(exam ~ tv_shows, data = dat, family = binomial(link = \"logit\"))\n# saturated\nfits <- glm(exam ~ 0 + id, data = dat, family = binomial(link = \"logit\"))\n```\n:::\n\n\n## Deviance - Example \n\nWe can calculate the residual deviance:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n-2*(logLik(fit) - logLik(fits))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 'log Lik.' 126.3001 (df=2)\n```\n:::\n\n```{.r .cell-code}\ndeviance(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 126.3001\n```\n:::\n:::\n\n\nWe can calculate the null deviance:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n-2*(logLik(fit0) - logLik(fits))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 'log Lik.' 130.6836 (df=1)\n```\n:::\n\n```{.r .cell-code}\ndeviance(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 130.6836\n```\n:::\n:::\n\n\n## $R^2$\n\nCompared to the standard linear regression, there are multiple ways to calculate an $R^2$ like measure for GLMs and there is no consensus about the most appropriate method. There are some useful resources:\n\n- https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/\n\nTo note, some measures are specific for the binomial GLM while other measures can be applied also to other GLMs (e.g., the poisson)\n\n## $R^2$\n\nWe will se:\n\n- McFadden's pseudo-$R^2$ (for GLMs in general)\n- Tjur's $R^2$ (only for binomial/binary models)\n\n## McFadden's pseudo-$R^2$\n\nThe McFadden's pseudo-$R^2$ compute the ratio between the log-likelihood of the intercept-only (i.e., null) model and the current model[@McFadden1987-qq]:\n\n$$\nR^2 = 1 - \\frac{\\log(\\mathcal{L_{current}})}{\\log(\\mathcal{L_{null}})}\n$$\n\nThere is also the adjusted version that take into account the number of parameters of the model. In R can be computed manually or using the `performance::r2_mcfadden()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nperformance::r2_mcfadden(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # R2 for Generalized Linear Regression\n#>        R2: 0.034\n#>   adj. R2: 0.018\n```\n:::\n:::\n\n\n## Tjur's $R^2$\n\nThis measure is the easiest to interpret and calculate but can only be applied for binomial binary models [@Tjur2009-ml]. Is the absolute value of the difference between the proportions of correctly classifying $y = 1$ and $y = 0$ from the model:\n\n\\begin{align*}\np_1 = p(y_i = 1 |\\hat y_i = 1) \\\\\np_2 = p(y_i = 0 |\\hat y_i = 0) = 1 - p_1 \\\\\nR^2 = |p_1 - p_2|\n\\end{align*}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nperformance::r2_tjur(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Tjur's R2 \n#> 0.5654064\n```\n:::\n:::\n\n\n## Residuals\n\nThe main problem of GLM is that the mean and the variance are linked. For example, the mean of a binomial distribution is $np$ and the variance is $np(1-p)$. In the standard linear model we have two parameters, $\\mu$ and the residual $\\sigma$ that are independent.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 0.1 + 0.6 * x + rnorm(1000)\nfit <- lm(y ~ x)\nri_lm <- residuals(fit) / sigma(fit)\nplot(fitted(fit), ri_lm, \n     ylab = \"Fitted Values\",\n     xlab = \"Standardized Residuals\")\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-105-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Residuals\n\nWhen using a linear model (thus assuming a constant $\\sigma$ and independence between mean and variance) the residuals pattern is very different:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- rpois(1000, exp(log(10) + log(1.5) * x))\nfit_poi <- lm(y ~ x)\n\nplot(fitted(fit_poi), rstandard(fit_poi),\n     xlab = \"Standardized Residuals\",\n     ylab = \"Fitted Values\")\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-106-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Residuals\n\nAs for standard linear models there are different types of residuals:\n\n- raw (response) residuals\n- pearson residuals\n- deviance residuals\n- standardized residuals\n\n## Raw Residuals\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nRaw residuals, also called response residuals are the simplest type of residuals. They are calculated as in standard regression as:\n\n\\begin{align*}\nr_i = y_i - \\hat y_i\n\\end{align*}\n\nWhere $\\hat y_i$ are the fitted values where the inverse of the link function has been applied.\n\nIn R:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# equivalent to residuals(fit, type = \"response\") \nri <- fit$y - fitted(fit)\nri[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> 0.56826521 0.18039223 0.07097155 0.56848124 0.04399144\n```\n:::\n:::\n\n\nThe problem is that in GLMs the mean and the variance of the distribution are not independent, creating problems in residual analysis.\n\n## Raw Residuals\n\nWe can use the function `car::residualPlot()` to plot different type of residuals against fitted values:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncar::residualPlot(fit, type = \"response\")\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-109-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Why raw residuals are problematic?\n\nThis plot^[Adapted from Dunn (2018), Fig. 8.1] shows an example with the same residual for two different $x$ values on a Poisson GLM. Beyond the model itself, the same residual can be considered as extreme for low $x$ values and plausible for high $x$ values:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-110-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Binned (raw) Residuals\n\nGelman and colleagues [@Gelman2020-tg, @Gelman2006-pc] proposed a type of residuals called **binned residuals** to solve the problem of the previous plot for Binomial GLMs:\n\n- divide the fitted values into $n$ bins. The number is arbitrary but we need each bin to have enough observation to compute a reliable average\n- calculate the average fitted value and residual for each bin\n- for each bin we can compute the standard error as $SE = \\frac{\\hat p_j (1 - p_j)}{n_j}$ where $p_j$ is the average fitted probability and $n_j$ is the number of observation in the bin $j$\n- Then we can plot each bin and the confidence intervals (e.g., as $\\pm 2*SE$) where ~95% of binned residuals should be within the CI if the model is true\n\n## Binned (raw) Residuals\n\nWe can use the `arm::binnedplot()` function to automatically create and plot the binned residuals:\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\npar(mfrow = c(1,2))\nplot(x, y, xlab = \"Expected Values\", ylab = \"Raw Residual\", main = \"Raw Residual Plot\")\nbinnedplot(x,y)\n```\n\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-112-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Pearson residuals\n\nPearson residuals are raw residuals divided by the standard deviation of each residual. Given that the mean-variance relationship of GLMs, dividing by the standard deviation partially solve the mean-variance relationship. The denominator can be calculated just using the appropriate variance formula for that specific GLM.\n\n$$\nr_i = \\frac{y_i - \\hat y_i}{\\sqrt{V(\\hat y_i)}}\n$$\n\n## Pearson vs Raw residuals\n\nWe can see the difference for a Poisson model^[We are using a Poisson model only because the residual pattern is more clear compared to a binomial model] when using raw vs pearson residuals. The non-constant variance is controlled on the right.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-113-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Pearson residuals\n\nFor the Binomial (Bernoulli) GLM, the variance is calculated as $\\hat p(1 - \\hat p)$ where $\\hat p$ is the residual value.\n\n$$\nr_i = \\frac{y_i - \\hat y_i}{\\sqrt{\\hat y_i(1 - \\hat y_i)}}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# equivalent to residuals(fit, type = \"pearson\")\nyi <- fitted(fit)\nri_pearson <- ri / sqrt(yi * (1 - yi))\nri_pearson[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> 1.17341398 0.42948479 0.14213499 1.21450070 0.09047435\n```\n:::\n:::\n\n\n## Deviance residuals\n\nDeviance residuals are based on the residual deviance that we defined before. In fact, the residual deviance was just the sum of squared deviance residuals.\n\n$$\nr_i = sign(y_i - \\hat y_i) \\sqrt{-2[\\log \\mathcal{L}y_{i_{current}} - \\log \\mathcal{L}y_{i_{saturated}}]}\n$$\nWhere $sign$ is the sign of the raw residual $i$. For the Bernoulli model the $\\log \\mathcal{L}y_{i_{saturated}}$ is always 0.\n\n## Deviance Residuals\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-115-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Deviance Residuals \n\nTo calculate and demonstrate manually the deviance residuals we can compute them manually in R:\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# residual(fit, type = \"deviance\")\nyhat <- fitted(fit) # fitted\ny <- fit$y # actual values\n\n# the likelihood is dbinom\nri_dev <- sign(y - yhat) * sqrt(-2*(log(dbinom(y, 1, yhat)) - log(dbinom(y, 1, y))))\n```\n:::\n\n\n## Deviance Residuals \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# notice that the log lik of the saturated model log(dbinom(y, 1, y)) is 0\nlog(dbinom(y, 1, y))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n#>  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 \n#> 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \n#>  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n```\n:::\n\n```{.r .cell-code}\nri_dev[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> -0.2370588  0.3033530 -1.0310244  0.2331303 -0.8429485\n```\n:::\n\n```{.r .cell-code}\nresiduals(fit, type = \"deviance\")[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> -0.2370588  0.3033530 -1.0310244  0.2331303 -0.8429485\n```\n:::\n:::\n\n\n## Quick recap about hat values in linear regression\n\n\\label{hatvalues-recap}\n\nThe **hat matrix** $H$ is calculated as $H = X \\left(X^{\\top} X \\right)^{-1} X^{\\top}$ is a $n \\times n$ matrix where $n$ is the number of observations. The diagonal of the $H$ matrix contained the hat values or leverages.\n\nThe $i^{th}$ leverage score ($h_{ii}$) is interpreted as the weighted distance between $x_i$ and the mean of $x_i$'s. In practical terms is the $i^{th}$ observed value influence the $i^{th}$ fitted value. An high leverage suggest that the observation is far from the mean of predictors and have an high influence on the fitted values.\n\n- $h_{ii}$ ranges between 0 and 1\n- The sum of all $h_{ii}$ values is the number of parameters $p$\n- As a rule of thumb, an observation have an high leverage if $h_{ii} > 2 \\bar h$ where $\\bar h$ is the average hat value\n\n## Quick recap about hatvalues in linear regression\n<!-- TODO add fox 11.2 reference -->\n\nFor a simple linear regression ($y \\sim x$) the hat values are calculated as:\n\n$$\nh_i = \\frac{1}{n} + \\frac{(X_i - \\bar X)^2}{\\sum^n_{j = 1}(X_i - \\bar X)^2}\n$$\n\nIn R the function `hatvalues()` return the diagonal of the $H$ matrix for `glm` and `lm`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhatvalues(fit)[1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5          6          7 \n#> 0.02874015 0.03492581 0.03968557 0.02782301 0.04357230 0.04652508 0.04435804 \n#>          8          9         10 \n#> 0.04012613 0.03948651 0.04743780\n```\n:::\n:::\n\n\nTo note, for GLM and multiple regression in general, the equation is different and more complicated but the intepretation and the R implementation is the same.\n\n## Standardized Residuals\n\nBoth the response, pearson and deviance residuals can be considered as raw residuals. We can standardize residuals by dividing for the standard error computed with the hat values. In this way, the distribution will be approximately normal with $\\mu = 0$ and $\\sigma = 1$.\n\n$$\nr_{s_i} = \\frac{r_i}{\\sqrt{(1 - \\hat h_{ii})}}\n$$\n\nWhere $r_i$ can be raw, pearson or deviance residuals.\n\n## Standardized Residuals\n\nIn R they can be extracted using `rstandard()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrstandard(fit, type = \"pearson\")[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> -0.1712897  0.2208858 -0.8546823  0.1683326 -0.6678440\n```\n:::\n\n```{.r .cell-code}\nrstandard(fit, type = \"deviance\")[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> -0.2405406  0.3087934 -1.0521126  0.2364427 -0.8619359\n```\n:::\n:::\n\n\n## Standardized Residuals {.allowframebreaks}\n\nWe can try to manually calculate the residuals to better understand.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nyhat <- fitted(fit) # fitted\nyi <- fit$y # observed\nhi <- hatvalues(fit) # diagonal of the hat matrix\n\n# pearson residuals\npi <- (yi - yhat) / sqrt(yhat * (1 - yhat))\n\n# standardized\npis <- pi / sqrt(1 - hi)\npis[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> -0.1712897  0.2208858 -0.8546823  0.1683326 -0.6678440\n```\n:::\n\n```{.r .cell-code}\nrstandard(fit, type = \"pearson\")[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> -0.1712897  0.2208858 -0.8546823  0.1683326 -0.6678440\n```\n:::\n:::\n\n\n## Standardized Residuals {.allowframebreaks}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# deviance (for binomial GLM the loglik of the saturated model is 0)\ndi <- sign(yi - yhat) * sqrt(-2*log(dbinom(y, 1, yhat)))\n\n# standardized\ndis <- di / sqrt(1 - hi)\n\ndis[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> -0.2405406  0.3087934 -1.0521126  0.2364427 -0.8619359\n```\n:::\n\n```{.r .cell-code}\nrstandard(fit, type = \"deviance\")[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>          1          2          3          4          5 \n#> -0.2405406  0.3087934 -1.0521126  0.2364427 -0.8619359\n```\n:::\n:::\n\n\n## Quantile residuals \n\nThe **quantile residuals** is another proposal for residual analysis. The idea is to map the quantile of the cumulative density function (CDF) of the random component into the CDF of the normal distribution.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-123-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Quantile residuals\n\n**Quantile residuals** are very useful especially for Discrete GLMs (binomial and poisson) and are exactly normally distributed (under respected model assumptions) compared to **deviance** and **pearson** residuals [@Dunn1996-yd]. They can be calculated using the `statmod::qresid(fit)` function. Authors suggest to run the function 4 times to disentagle between the randomization and the systematic component.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstatmod::qresid(fit)[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] -0.33677932  1.04616589 -0.43878900  0.01511622 -1.07265867\n```\n:::\n\n```{.r .cell-code}\nstatmod::qresid(fit)[1:5] # different every time\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1]  1.2349067 -0.6689038  0.2171433 -0.9988869 -0.4189008\n```\n:::\n:::\n\n\n## Quantile residuals \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-125-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## More on residuals\n\nResiduals for GLMs are complicated. To have a more detailed and clear overview see:\n\n- @Agresti2015-cz, Sections 4.4.5, 4.4.6\n- @Dunn2018-ww, Chapter 8\n\n## Classification accuracy/Error rate\n\nThe **error rate** (ER) is defined as the proportion of cases for which the deterministic prediction i.e. guessing $y_i = 1$ if $logit^{-1}(\\hat y_i) > 0.5$ and guessing $y_i = 0$ if $logit^{-1}(\\hat y_i) > 0.5$ is wrong. Clearly, $1 - ER$ is the **classification accuracy**.\n\nI wrote the `error_rate` function that simply compute the error rate of a given model:\n\n\n::: {.cell layout-align=\"center\"}\n```r\nerror_rate <- function(fit){\n    pi <- predict(fit, type = \"response\")\n    yi <- fit$y\n    cr <- mean((pi > 0.5 & yi == 1) | (pi < 0.5 & yi == 0))\n    1 - cr # error rate\n}\n```\n:::\n\n\n## Classification accuracy/Error rate\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nerror_rate(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.14\n```\n:::\n:::\n\n\nWe could compare the error rate of a given model with the error rate of the null model or another similar model (with a model comparison approach):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit0 <- update(fit, . ~ -x) # removing the x predictor, now intercept only model\nerror_rate(fit0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.48\n```\n:::\n\n```{.r .cell-code}\n# the error rate of the null model is ... greater/less than the actual model\ner_ratio = error_rate(fit0)/error_rate(fit)\n```\n:::\n\n\nThe **error rate** of the null model is 3.429 times greater than the actual model.\n\n## Classification accuracy/Error rate\n\n- For a given model, the error rate should be less than $0.5$, otherwise setting all $\\beta$'s to 0 (i.e., null model) would be considered a better model [@Gelman2020-tg].\n\n- For example if the average $p$ in a dataset is $\\overline p = 0.3$ means that a null model would have an error rate of $0.3$ and a classification accuracy of $1 - \\overline p = 0.7$.\n\n- Including predictors we aim to reduce the error rate (compared to the null model) because the ability to correctly classify an observation increase.\n\n- The error rate can be misleading, see @Gelman2020-tg (pp. 255-256)\n\n## Outliers and influential observations\n\nIdentification of influential observation and outliers of GLMs is very similar to standard regression models. We will briefly see:\n\n- Cook Distances\n- DFBETAs\n\n## Cook Distances\n\nThe Cook Distance of an observation $i$ measured the impact of that observation on the overall model fit. If removing the observation $i$ has an high impact, the observation $i$ is likely an influential observation. For GLMs they are defined as:\n\n\\begin{align*}\nD_i = \\frac{r_i^2}{\\phi p} \\frac{h_{ii}}{1 - h_{ii}}\n\\end{align*}\n\nWhere $p$ is the number of model parameters, $r_i$ are the standardized pearson residuals (`rstandard(fit, type = \"pearson\")`) and $h_{ii}$ are the hatvalues (leverages). $\\phi$ is the dispersion parameter of the GLM that for binomial and poisson models is fixed to 1 (see Dunn (2018, Table 5.1)) Usually an observation is considered influential if $D_i > \\frac{4}{n}$ where $n$ is the sample size.\n\n## DFBETAs\n\nDFBETAs measure the impact of the observation $i$ on the estimated parameter $\\beta_j$:\n\n\\begin{align*}\nDFBETAS_i = \\frac{\\beta_j - \\beta_{j(i))}}{\\sigma_{\\beta_{j(i)}}}\n\\end{align*}\n\nWhere $i$ denote the parameters and standard error on a model fitted without the $i$ observation^[Note that you are not required to re-fit the model to estimate the DFBETAs, you can use the $H$ matrix, see https://en.wikipedia.org/wiki/Influential_observation]. Usually an observation is considered influential if $|DFBETAs_{i}| > \\frac{2}{\\sqrt{n}}$ where $n$ is the sample size.\n\n## Extracting influence measures\n\nIn R we can use the `influence.measures()` function to calculate each influence measure explained before^[The function actually computes also other influence measures, see Dunn (2018, section 8.8.3) for other details].\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit <- update(fit, data = fit$model[1:50, ])\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninfl <- influence.measures(fit)$infmat\nhead(infl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>        dfb.1_      dfb.x       dffit    cov.r       cook.d        hat\n#> 1 -0.04419414 0.04109800 -0.04442749 1.070827 0.0004340963 0.02874015\n#> 2 -0.04672053 0.05681844  0.06310261 1.075710 0.0008828590 0.03492581\n#> 3 -0.11865551 0.05713533 -0.23265873 1.028011 0.0150937972 0.03968557\n#> 4 -0.03348170 0.03972704  0.04294688 1.069920 0.0004054759 0.02782301\n#> 5 -0.14588644 0.10150547 -0.19921442 1.051194 0.0101596403 0.04357230\n#> 6 -0.07575414 0.10700698  0.14303484 1.074641 0.0048052405 0.04652508\n```\n:::\n:::\n\n\nThe first two columns are the DFBETAs for each parameter, the `cook.d` columns contains the Cook Distances and `hat` is the diagonal of the $H$ matrix.\n\n## Plotting influence measures\n\nI wrote the `cook_plot()` function to easily plot the cook distances along with the identification of influential observations:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncook_plot(fit)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-132-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Plotting influence measures\n\nI wrote the `dfbeta_plot()` function to easily plot the cook distances along with the identification of influential observations:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndfbeta_plot(fit)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-134-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Binomial vs Binary\n\nThere are several practical differences between binomial and binary models:\n\n- data structure\n- fitting function in R\n- residuals and residual deviance\n- type of predictors \n\n## Binomial vs Binary data structure\n\nThe most basic Binomial regression is a vector of binary $y$ values and a continuous or categorical predictor. Let's see a common data structure in this case:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nn <- 30\nx <- runif(n, 0, 1)\ndat <- sim_design(ns = n, nx = list(x = x))\nb0 <- qlogis(0.01)\nb1 <- 8\n\ndat |> \n    sim_data(plogis(b0 + b1*x), \"binomial\") |> \n    select(-lp) |> \n    round(2) |> \n    filor::trim_df(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 3\n#>   id    x     y    \n#>   <chr> <chr> <chr>\n#> 1 1     0.85  1    \n#> 2 2     0.16  0    \n#> 3 3     0.08  0    \n#> 4 4     0.17  0    \n#> 5 ...   ...   ...  \n#> 6 27    0.52  1    \n#> 7 28    0.64  1    \n#> 8 29    0.11  0    \n#> 9 30    0.54  1\n```\n:::\n:::\n\n\n## Binomial vs Binary data structure\n\nOr equivalently with a categorical variable:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- 15\nx <- c(\"a\", \"b\")\ndat <- sim_design(n, cx = list(x = x))\nb0 <- qlogis(0.4)\nb1 <- log(odds_ratio(0.7, 0.4))\n\ndat |> \n    sim_data(plogis(b0 + b1*x_c), \"binomial\") |> \n    dplyr::select(-x_c, -lp) |> \n    filor::trim_df(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 3\n#>   id    x     y    \n#>   <chr> <chr> <chr>\n#> 1 1     a     1    \n#> 2 2     b     0    \n#> 3 3     a     0    \n#> 4 4     b     0    \n#> 5 ...   ...   ...  \n#> 6 27    a     0    \n#> 7 28    b     1    \n#> 8 29    a     0    \n#> 9 30    b     0\n```\n:::\n:::\n\n\n## Binomial vs Binary data structure\n\nWhen using a Binomial data structure we count the number of success for each level of $x$. `nc` is the number of 1 responses, `nf` is the number of 0 response out of `nt` trials:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- seq(0, 1, 0.05)\nnt <- 10\nnc <- rbinom(length(x), nt, plogis(qlogis(0.01) + 8*x))\ndat <- data.frame(x, nc, nf = nt - nc,  nt)\n\ndat |> \n    filor::trim_df(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 4\n#>   x     nc    nf    nt   \n#>   <chr> <chr> <chr> <chr>\n#> 1 0     0     10    10   \n#> 2 0.05  0     10    10   \n#> 3 0.1   1     9     10   \n#> 4 0.15  0     10    10   \n#> 5 ...   ...   ...   ...  \n#> 6 0.85  9     1     10   \n#> 7 0.9   8     2     10   \n#> 8 0.95  9     1     10   \n#> 9 1     10    0     10\n```\n:::\n:::\n\n\n## Binomial vs Binary data structure\n\nWith a categorical variable we have essentially a contingency table:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- c(\"a\", \"b\")\nnt <- 10\nnc <- rbinom(length(x), nt, plogis(qlogis(0.4) + log(odds_ratio(0.7, 0.4))*ifelse(x == \"a\", 1, 0)))\n\ndatc <- data.frame(x, nc, nf = nt - nc,  nt)\ndatc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 4\n#>   x        nc    nf    nt\n#>   <chr> <int> <dbl> <dbl>\n#> 1 a         5     5    10\n#> 2 b         4     6    10\n```\n:::\n:::\n\n\n## Binomial vs Binary: data structure\n\nClearly, expanding or aggregating data is the way to convert a binary into a binomial data structure and the opposite:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# from binomial to binary\nbin_to_binary(datc, nc, nt) |> \n    select(y, x) |> \n    filor::trim_df()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 2\n#>   y     x    \n#>   <chr> <chr>\n#> 1 1     a    \n#> 2 1     a    \n#> 3 1     a    \n#> 4 1     a    \n#> 5 ...   ...  \n#> 6 0     b    \n#> 7 0     b    \n#> 8 0     b    \n#> 9 0     b\n```\n:::\n:::\n\n\n## Binomial vs Binary: data structure\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# from binary to binomial\nbin_to_binary(datc, nc, nt)  |>\n    binary_to_bin(y, x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 2 × 4\n#>   x        nc    nf    nt\n#>   <chr> <dbl> <dbl> <int>\n#> 1 a         5     5    10\n#> 2 b         4     6    10\n```\n:::\n:::\n\n\n## Binomial vs Binary: multilevel disclaimer\n\n- Clearly, in the previous examples, each row correspond to a single observation (in the binary model) or a condition (in the binomial model). Furthermore each row/observation/participants is assumed to be independent.\n\n- If participants performed multiple trials for each condition, we can still use a binomial or binary model BUT we need to take into account the multilevel structure.\n\n- In practice, we need to use a mixed-effects GLM, for example with the `lme4::glmer()` package specifying the appropriate random structure.\n\n## Binomial vs Binary: - fitting function in R\n\nThere is a single way to implement a binary model in R and two ways for the binomial version:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# binary regression\nglm(y ~ x, family = binomial(link = \"logit\"))\n\n# binomial with cbind syntax, nc = number of 1s, nf = number of 0s, nc + nf = nt\nglm(cbind(nc, nf) ~ x, family = binomial(link = \"logit\"))\n\n# binomial with proportions and weights, equivalent to the cbind approach, nt is the total trials\nglm(nc/nt ~ x, weights = nt, binomial(link = \"logit\"))\n```\n:::\n\n\n## Binomial vs Binary: residuals and residual deviance\n\nA more relevant difference is about the residual analysis. The binary regression has different residuals compared to the binomial model fitted on the same dataset^[To note, the **binned residuals** could be considered as an attempt to mitigate the binary residuals problem by creating bins of fitted/residual values similarly to fitting a binomial model.].\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_binomial <- glm(nc/nt ~ x, weights = nt, data = dat_binomial, family = binomial(link = \"logit\"))\nfit_binary <- glm(y ~ x, data = dat_binary, family = binomial(link = \"logit\"))\n```\n:::\n\n\n## Binomial vs Binary: residuals and residual deviance\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-144-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Binomial vs Binary: residuals and residual deviance\n\nThe residual deviance is also different. In fact, there is more residual deviance on the binary compared to the binomial model. However, comparing two binary and binomial models actually leads to the same conclusion. In other terms the deviance seems to be on a different scale^[Thanks to Prof. Altoè for this suggestion]:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit0_binary <- update(fit_binary, . ~ -x) # null binary model\nfit0_binomial <- update(fit_binomial, . ~ -x) # null binary model\n```\n:::\n\n\n## Binomial vs Binary: residuals and residual deviance\n\nIn fact, if we compare the full model with the null model in both binary and binomial version, the LRT is the same but the deviance is on a different scale. Comparing a binary with a binomial model could be completely misleading.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(fit_binomial, fit0_binomial, test = \"Chisq\")\n#> # A tibble: 2 × 5\n#>   `Resid. Df` `Resid. Dev`    Df Deviance `Pr(>Chi)`\n#>         <dbl>        <dbl> <dbl>    <dbl>      <dbl>\n#> 1          19         14.4    NA      NA   NA       \n#> 2          20        148.     -1    -133.   8.27e-31\nanova(fit_binary, fit0_binary, test = \"Chisq\")\n#> # A tibble: 2 × 5\n#>   `Resid. Df` `Resid. Dev`    Df Deviance `Pr(>Chi)`\n#>         <dbl>        <dbl> <dbl>    <dbl>      <dbl>\n#> 1         208         156.    NA      NA   NA       \n#> 2         209         289.    -1    -133.   8.27e-31\n```\n:::\n\n\n## Binomial vs Binary: type of predictors \n\nThis point is less relevant in this course but important in general. Usually, **binary regression** is used when the predictor is at the *trial level* whereas **binomial regression** is used when the predictor is at the *participant level*. When both levels are of interests one should use a mixed-effects model where both levels can be modeled.\n\n- the probability of correct responses during an exam as a function of the question difficulty (each trial/row could have a different $x$ level)\n- the probability of passing the exam as a function of the high-school background regardless of having multiple trials, each trial/row has the same $x_i$ for the participant $i$\n\n## Binomial vs Binary: type of predictors \n\n> The probability of correct responses during an exam as a function of the question difficulty\n\n- each question (i.e., *trial*) has a 0/1 response and a difficulty level\n- we are modelling a single participant, otherwise we need a multilevel (mixed-effects) model\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ndat <- expand_grid(id = 1, question = 1:30)\ndat$y <- rbinom(nrow(dat), 1, 0.7)\ndat$difficulty <- sample(1:5, nrow(dat), replace = TRUE)\n\ndat |> \n    select(id, question, difficulty, y) |> \n    filor::trim_df()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 4\n#>   id    question difficulty y    \n#>   <chr> <chr>    <chr>      <chr>\n#> 1 1     1        1          1    \n#> 2 1     2        3          1    \n#> 3 1     3        3          1    \n#> 4 1     4        1          0    \n#> 5 ...   ...      ...        ...  \n#> 6 1     27       1          1    \n#> 7 1     28       5          1    \n#> 8 1     29       1          0    \n#> 9 1     30       1          1\n```\n:::\n:::\n\n\n## Binomial vs Binary: type of predictors \n\n> the probability of passing the exam as a function of the high-school background\n\n- each \"background\" has different students that passed or not the exam (0/1)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 4 × 4\n#>   background nc    nf    nt   \n#>   <chr>      <chr> <chr> <chr>\n#> 1 math       20    10    30   \n#> 2 chemistry  16    4     20   \n#> 3 art        4     6     10   \n#> 4 sport      15    5     20\n```\n:::\n:::\n\n\nOr the binary version:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 9 × 5\n#>   y     background nc    nf    nt   \n#>   <chr> <chr>      <chr> <chr> <chr>\n#> 1 1     math       20    10    30   \n#> 2 1     math       20    10    30   \n#> 3 1     math       20    10    30   \n#> 4 1     math       20    10    30   \n#> 5 ...   ...        ...   ...   ...  \n#> 6 0     sport      15    5     20   \n#> 7 0     sport      15    5     20   \n#> 8 0     sport      15    5     20   \n#> 9 0     sport      15    5     20\n```\n:::\n:::\n\n\n## Binomial vs Binary: type of predictors \n\n- To note that despite we can convert between the binary/binomial, the two models are not always the same. The *high-school background example* can be easily modelled either with a binary or binomial model because the predictor is at the participant level that coincides with the trial level.\n- On the other side, the *question difficulty example* can only be modelled using a binary regression because each trial (0/1) has a different value for the predictor\n- To include both predictors or to model multiple participants on the *question difficulty example* we need a mixed-effects model where both levels together with the repeated-measures can be handled.\n- a very clear overview of this topic can be found here https://www.rensvandeschoot.com/tutorials/generalised-linear-models-with-glm-and-lme4/\n\n# Probit link {.section}\n\n## Probit link\n\n- The mostly used *link function* when using a binomial GLM is the **logit link**. The **probit** link is another *link function* that can be used. The overall approach is the same between **logit** and **probit** models. The only difference is the parameter interpretation (i.e., no odds ratios) and the specific link function (and the inverse) to use.\n- The **probit** model use the **cumulative normal distribution** but the actual difference with a **logit** functions is neglegible.\n\n## Probit link\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-150-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## Probit link\n\nWhen using the **probit link** the parameters are interpreted as difference in *z-scores* associated with a unit increase in the predictors. In fact probabilities are mapped into *z-scores* using the cumulative normal distribution.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np1 <- 0.7\np2 <- 0.5\n\nqlogis(c(p1, p2)) # log(odds(p1)), logit link\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.8472979 0.0000000\n```\n:::\n\n```{.r .cell-code}\nqnorm(c(p1, p2)) # probit link\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.5244005 0.0000000\n```\n:::\n\n```{.r .cell-code}\nlog(odds_ratio(p1, p2)) # ~ beta1, logit link\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.8472979\n```\n:::\n\n```{.r .cell-code}\npnorm(p1) - pnorm(p2) # ~beta1, probit link\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 0.06657389\n```\n:::\n:::\n\n\n## Probit link\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-binomial-glm_files/figure-revealjs/unnamed-chunk-152-1.svg){fig-align='center' width=672}\n:::\n:::\n\n\n## References\n",
    "supporting": [
      "02-binomial-glm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}